[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "DataViz.html",
    "href": "DataViz.html",
    "title": "DataViz Makeover",
    "section": "",
    "text": "There are two dataviz makeover exercises that are due throughout the term. I will post one or two data visualisation and you are required to critic, suggest ways for improvement and rework the data visualisation. Maybe you retell the story more effectively, or find a new story in the data. I am curious to see the different approaches you all take.\nThe purpose of the makeover is to improve on the original visualisation. Focus on what works, what doesn’t work, why those things don’t work, and how you made it better. You should try stick to the fields in the data set provided and improve upon the original visualisation. However, if supplementing the data helps you tell a better story, go for it!"
  },
  {
    "objectID": "DataViz.html#dataviz-makeover-topics",
    "href": "DataViz.html#dataviz-makeover-topics",
    "title": "DataViz Makeover",
    "section": "DataViz Makeover Topics",
    "text": "DataViz Makeover Topics\n\nDataViz Makeover 1\nDataViz Makeover 2"
  },
  {
    "objectID": "DataViz.html#submission-instructions",
    "href": "DataViz.html#submission-instructions",
    "title": "DataViz Makeover",
    "section": "Submission Instructions",
    "text": "Submission Instructions\n\nThe write-up of the DataViz Makeover must be in Quarto html document format. You are required to publish the write-up on Netlify.\nThe R project of the DataViz Makeover must be pushed onto your Github repository.\nThe DataViz Makeover must be prepared by using Tableau Desktop. The final workbook must be uploaded onto Tableau Public.\nAll DataViz Makeover have to be completed by Sunday before mid-night 11.59pm. You are required to provide the links to the DataViz Makeover write-up, github repository and Tableau Public onto eLearn (i.e. DataViz Makeover section) as shown in the screenshot below:"
  },
  {
    "objectID": "DataViz.html#for-your-reference",
    "href": "DataViz.html#for-your-reference",
    "title": "DataViz Makeover",
    "section": "For your reference",
    "text": "For your reference\n\nFrom seniors\n\nDataViz Makeover Blog Link AY2020-2021 Term 2\n\nDataViz Makeover 1 handout, sample web article and Tableau Public submission.\n\nDataViz Makeover AY2020-2021 Term 3\n\nDataViz Makeover 1\n\nDataViz Makeover AY2021-22 January Term\n\nDataViz Makeover 1:\n\nLIN SHUYAN Best make-over design, simple but yet functional.\nSUN SHENGMEI Interesting makeover design and very detail step-by-step description especially on how to work with Tableau Data Prep.\n\nDataViz Makeover 2\n\nAng Bi Lian Effective used of Tableau Story.\nLin Shuyan Creative implementation of linked views.\nMin Xiaoqi Effective used of interactive tooltip.\n\n\n\n\n\nFrom external sources\n\nMakeover Monday, especially:\n\nGallery\nOur Makeover\nWebinars\nblog\n\nStory Telling with Data, especially:\n\nCommunity\nBlog"
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "Git and Github",
    "section": "",
    "text": "Happy Git and GitHub for the useR. Highly recommended to beginners."
  },
  {
    "objectID": "git.html#gitgithub",
    "href": "git.html#gitgithub",
    "title": "Git and Github",
    "section": "git/github",
    "text": "git/github\n\ngithub doc\nGitHub and RStudio"
  },
  {
    "objectID": "git.html#blog-post",
    "href": "git.html#blog-post",
    "title": "Git and Github",
    "section": "Blog post",
    "text": "Blog post\n\nGetting starting with git and GitHub using RStudio\ngit\nTransform a folder as git project synchronized on Github or Gitlab\nRecovering from common Git predicaments\ngit in RStudio\nSolving git(GitHub) token issue"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#content",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#content",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Content",
    "text": "Content\n\nIntroducing Tidyverse\nggplot2, The Layered Grammar of Graphics\n\nThe Essential Grammatical Elements in ggplot2\nDesigning Analytical Graphics with ggplot2\n\nggplot Wizardry"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#introducing-tidyverse",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#introducing-tidyverse",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Introducing Tidyverse",
    "text": "Introducing Tidyverse\ntidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#getting-started",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Getting started",
    "text": "Getting started\nInstalling and loading the required libraries\n\n\n\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\n\n\n\n\n\n\n\nNote\n\n\nThe code chunk on the right assumes that you already have pacman package installed. If not, please go ahead install pacman first.\n\n\n\n\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#getting-started-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#getting-started-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Getting Started",
    "text": "Getting Started\nImporting data\n\n\n\nThe code chunk below imports exam_data.csv into R environment by using read_csv() function of readr package.\nreadr is one of the tidyverse package.\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\n\nYear end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. Four of them are categorical data type and the other three are in continuous data type.\n\nThe categorical attributes are: ID, CLASS, GENDER and RACE.\nThe continuous attributes are: MATHS, ENGLISH and SCIENCE."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#introducing-ggplot",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#introducing-ggplot",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Introducing ggplot ",
    "text": "Introducing ggplot \n\n\n\nAn R package for declaratively creating data-driven graphics based on The Grammar of Graphics\nIt is part of the tidyverse family specially designed for visual exploration and communication.\nFor more detail, visit ggplot2 link."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#grammar-of-graphics",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#grammar-of-graphics",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Grammar of Graphics",
    "text": "Grammar of Graphics\n\n\n\nWilkinson, L. (1999) Grammar of Graphics, Springer.\nThe grammar of graphics is an answer to a question:\n\n\nWhat is a statistical graphic?\n\n\nGrammar of graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nTwo principles\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\n\n\n\nA good grammar will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978).\nA grammar provides a strong foundation for understanding a diverse range of graphics.\nA grammar may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nA Layered Grammar of Graphics\n\n\n\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\n\nReference: Hadley Wickham (2010) “A layered grammar of graphics.” Journal of Computational and Graphical Statistics, vol. 19, no. 1, pp. 3–28."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nThe ggplot() function and data argument\n\n\n\nLet us call the ggplot() function using the code chunk on the right.\nNotice that a blank canvas appears.\nggplot() initializes a ggplot object.\nThe data argument defines the dataset to be used for plotting.\nIf the dataset is not already a data.frame, it will be converted to one by fortify().\n\n\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-2",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-2",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nThe Aesthetic mappings\n\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency.\nEach visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-3",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-3",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with aes()\n\n\n\nThe code chunk on the right add the aesthetic element into the plot.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\nNotice that ggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-4",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-4",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom\n\n\n\n\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\n\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-5",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-5",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_bar\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-6",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-6",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_dotplot\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\n\n\n\n\n\n\nBe warned\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-7",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-7",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_dotplot\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-8",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-8",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_histogram()\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\nNote\n\n\nNote that the default bin is 30."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-9",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-9",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nModifying a geometric object by changing geom()\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-10",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-10",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nModifying a geometric object by changing aes()\n\n\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\nNote\n\n\nThis approach can be used to colour, fill and alpha of the geometric."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-11",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-11",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom-density\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\nReference: Kernel density estimation"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-12",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-12",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom-density\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-13",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-13",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_boxplot\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\n\nThe code chunk below plots boxplots by using geom_boxplot().]\n\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-14",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-14",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_boxplot\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\nReference: Notched Box Plots."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-15",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-15",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\ngeom objects can be combined\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +              #<<      \n  geom_point(position=\"jitter\", #<<\n             size = 0.5)        #<<"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-16",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-16",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_violin\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-17",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-17",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_violin() and geom_boxplot()\n\n\nThe code chunk below combined a violin plot and a boxplot to show the distribution of Maths scores by gender.]\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin(fill=\"light blue\") +\n  geom_boxplot(alpha=0.5)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-18",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-18",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nGeometric Objects: geom_point()\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-19",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-19",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nStatistics, stat\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-20",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-20",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with stat\n\n\n\nThe boxplots on the right are incomplete because the positions of the means were not shown.\nNext two slides will show you how to add the mean values on the boxplots."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-21",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-21",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with stat - the stat_summary() method\n\n\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-22",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-22",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with stat - the geom() method\n\n\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-23",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-23",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nHow to add a best fit curve on a scatterplot?\n\n\n\nThe scatterplot on the right shows the relationship of Maths and English grades of pupils.\nThe interpretability of this graph can be improved by adding a best fit curve."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-24",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-24",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nHow to add a best fit curve on a scatterplot?\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\nThe default method used is loess.]\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(size=0.5)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-25",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-25",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nHow to add a best fit curve on a scatterplot?\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-26",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-26",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nFacets\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data.\nFacets are an alternative to aesthetics for displaying additional discrete variables.\nggplot2 supports two types of factes, namely: facet_grid() and facet_wrap."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-27",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-27",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nfacet_wrap()\n\nfacet_wrap wraps a 1d sequence of panels into 2d.\nThis is generally a better use of screen space than facet_grid because most displays are roughly rectangular."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-28",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-28",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with facet_wrap()\n\n\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-29",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-29",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nfacet_grid() function\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables.\nIt is most useful when you have two discrete variables, and all combinations of the variables exist in the data."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-30",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-30",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with facet_grid()\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-31",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-31",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nCoordinates\n\nThe Coordinates functions map the position of objects onto the plane of the plot.\nThere are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian(): the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip(): a cartesian system with the x and y flipped.\ncoord_fixed(): a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap(): a coordinate system that approximates a good aspect ratio for maps."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-32",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-32",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nThemes\n\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include:\n\ntheme_gray() (default)\ntheme_bw()\ntheme_classic()\n\nA list of theme can be found at this link.\nEach theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title)."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-33",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#essential-grammatical-elements-in-ggplot2-33",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Essential Grammatical Elements in ggplot2",
    "text": "Essential Grammatical Elements in ggplot2\nWorking with theme\n\n\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis I",
    "text": "Designing Data-drive Graphics for Analysis I\nThe original design\n\n\nA simple vertical bar chart for frequency analysis. Critics:\n\ny-aixs label is not clear (i.e. count)\nTo support effective comparison, the bars should be sorted by their resepctive frequencies.\nFor static graph, frequency values should be added to provide addition information."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis I",
    "text": "Designing Data-drive Graphics for Analysis I\n\n\n\n\n\n\n\n\nThe makeover design\n\n\nWith reference to the critics on the earlier slide, create a makeover looks similar to the figure on the right.\n\n\n\n\nggplot(data=exam_data,\n       aes(x=reorder(RACE,RACE,\n                function(x)-length(x))))+\n  geom_bar() +\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i-2",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-i-2",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis I",
    "text": "Designing Data-drive Graphics for Analysis I\nThe makeover design\n\n\nThis code chunk uses fct_infreq() of forcats package.\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n  ggplot(aes(x = RACE)) + \n  geom_bar()+\n  ylim(0,220) +\n  geom_text(stat=\"count\", \n      aes(label=paste0(..count.., \", \", \n      round(..count../sum(..count..)*100,\n            1), \"%\")),\n      vjust=-1) +\n  xlab(\"Race\") +\n  ylab(\"No. of\\nPupils\") +\n  theme(axis.title.y=element_text(angle = 0))\n\n\nCredit: I learned this trick from Getting things into the right order of Prof. Claus O. Wilke, the author of Fundamentals of Data Visualization"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-ii",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-ii",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis II",
    "text": "Designing Data-drive Graphics for Analysis II\nThe original design"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-ii-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-ii-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis II",
    "text": "Designing Data-drive Graphics for Analysis II\n\n\n\n\n\n\n\n\nThe makeover design\n\n\n\nAdding mean and median lines on the histogram plot.\nChange fill color and line color\n\n\n\n\n\n\n\n\n\n\nThe code chunk:\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(MATHS,\n                                 na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=1) +\n  geom_vline(aes(xintercept=median(MATHS,\n                                  na.rm=T)),\n             color=\"grey30\",\n             linetype=\"dashed\", \n             size=1)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iii",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iii",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis III",
    "text": "Designing Data-drive Graphics for Analysis III\n\n\nThe original design\nThe histograms on the left are elegantly designed but not informative. This is because they only reveal the distribution of English scores by gender but without context such as all pupils.\n\n\n\n\n\n\n\n\n\n\n\n\nThe makeover design\n\n\nCreate a makeover looks similar to the figure below. The background histograms show the distribution of English scores for all pupils."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iii-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iii-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis III",
    "text": "Designing Data-drive Graphics for Analysis III\n\n\nThe code chunk\n\nd <- exam_data   \nd_bg <- d[, -3]  \n\nggplot(d, aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = d_bg, fill = \"grey\", alpha = .5) +\n  geom_histogram(colour = \"black\") +\n  facet_wrap(~ GENDER) +\n  guides(fill = FALSE) +  \n  theme_bw()\n\n\nThe makeover design"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iv",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iv",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis IV",
    "text": "Designing Data-drive Graphics for Analysis IV\nThe original design."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iv-1",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#designing-data-drive-graphics-for-analysis-iv-1",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Designing Data-drive Graphics for Analysis IV",
    "text": "Designing Data-drive Graphics for Analysis IV\n\n\n\n\n\n\n\n\nThe makeover design\n\n\nCreate a makeover looks similar to the figure on the right.\n\n\n\n\nggplot(data=exam_data, \n       aes(x=MATHS, y=ENGLISH)) +\n  geom_point() +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  geom_hline(yintercept=50,\n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1) + \n  geom_vline(xintercept=50, \n             linetype=\"dashed\",\n             color=\"grey60\",\n             size=1)\n\n\nA within group scatterplot with reference lines."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#reference",
    "href": "hands-on_ex/Hands-on_Ex01/Hands-on_Ex01-ggplot2.html#reference",
    "title": "Hands-on Exercise 1: Programming Elegant DataVis with ggplot2",
    "section": "Reference",
    "text": "Reference\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#content",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#content",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Content",
    "text": "Content\n\n\nBeyond ggplot2 Themes\nBeyond ggplot2 Annotation\nBeyond ggplot2 facet"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#getting-started",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Getting started",
    "text": "Getting started\nInstalling and loading the required libraries\n\n\n\nBefore we get started, it is important for us to ensure that the required R packages have been installed. If yes, we will load the R packages. If they have yet to be installed, we will install the R packages and load them onto R environment.\nThe chunk code on the right will do the trick.\n\n\n\n\npacman::p_load(tidyverse, patchwork, \n               ggthemes, hrbrthemes,\n               ggrepel)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-annotation",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-annotation",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 Annotation",
    "text": "Beyond ggplot2 Annotation\n\n\nOne of the challenge in plotting statistical graph is annotation, especially with large number of data points.\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-themes",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-themes",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 Themes",
    "text": "Beyond ggplot2 Themes\n\n\nggplot2 comes with eight built-in themes, they are: theme_gray(), theme_bw(), theme_classic(), theme_dark(), theme_light(), theme_linedraw(), theme_minimal(), and theme_void().\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +  \n  ggtitle(\"Distribution of Maths scores\") \n\n\n\nRefer to this link to learn more about ggplot2 Themes"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-facet",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#beyond-ggplot2-facet",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Beyond ggplot2 facet",
    "text": "Beyond ggplot2 facet\n\n\nIn this section, you will learn how to create composite plot by combining multiple graphs. First, let us create three statistical graphics.\n\n\np1 <- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\n\np2 <- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\n\n\n\n\np3 <- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#reference",
    "href": "hands-on_ex/Hands-on_Ex02/Hands-on_Ex02-Beyond_ggplot2.html#reference",
    "title": "Hands-on Exercise 2: Beyond ggplot2 Fundamentals",
    "section": "Reference",
    "text": "Reference\n\nPatchwork R package goes nerd viral\nggrepel\nggthemes\nhrbrthemes\nggplot tips: Arranging plots\nggplot2 Theme Elements Demonstration\nggplot2 Theme Elements Reference Sheet"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to create:\n\ninteractive data visualisation by using ggiraph and plotlyr packages,\nanimated data visualisation by using gganimate and plotlyr packages.\nVisualising univariate data with large number of categories by using rPackedBar package.\n\nAt the same time, you will also learn how to:\n\nreshape data by using tidyr package, and\nprocess, wrangle and transform data by using dplyr package."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#getting-started",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Getting Started",
    "text": "Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for compising multiple plots.\n\nThe solution:"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#importing-data",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#importing-data",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, Exam_data.csv provided will be used. Using read_csv() of readr package, import Exam_data.csv into R.\nThe solution:\n\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---ggiraph-methods",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\n\nggiraph is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detail explanation.\n\n\nTooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nComparing ggplot2 and ggiraph codes\nThe original ggplot2 code chunk.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5, \n               dotsize = 0.5) +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\n\nThe ggiraph code chunk.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              #<<\n    aes(tooltip = ID),                   #<<\n    stackgroups = TRUE,                  #<<\n    binwidth = 1,                        #<<\n    method = \"histodot\") +               #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  #<<\n  ggobj = p,                             #<<\n  width_svg = 6,                         #<<\n  height_svg = 6*0.618                   #<<   \n)                                        #<<\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip <- c(paste0(     #<<\n  \"Name = \", exam_data$ID,         #<<\n  \"\\n Class = \", exam_data$CLASS)) #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), #<<\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nInteractivity: By hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\nCustomising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css <- \"background-color:white; #<<\nfont-style:bold; color:black;\" #<<\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #<<\n    opts_tooltip(    #<<\n      css = tooltip_css)) #<<\n)                                        \n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nDisplaying statistics on tooltip\n\ntooltip <- function(y, ymax, accuracy = .01) {   #<<\n  mean <- scales::number(y, accuracy = accuracy) #<<\n  sem <- scales::number(ymax - y, accuracy = accuracy) #<<\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem) #<<\n} #<<\n\ngg_point <- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  #<<\n                     tooltip(y, ymax))),  #<<\n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  #<<\n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nCode chunk on the left shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nHover effect with data_id aesthetic\nCode chunk below show the second interactive feature of ggiraph, namely data_id.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             #<<\n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        #<<\n    opts_hover(css = \"fill: #202020;\"),  #<<\n    opts_hover_inv(css = \"opacity:0.2;\") #<<\n  )                                      #<<  \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\nNote: Different from Slide 9, in this example the ccs customisation request are encoded directly.\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, #<<\n        data_id = CLASS),#<<              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on ther web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              #<<\n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\nCoordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation on the right.\n\nwhen a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\n\n\n\n\n\n\n\n\n\nCoordinated Multiple Views with ggiraph\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\n\np2 <- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + #<<\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 / p2), #<<\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---plotly-methods",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\n\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics.\nDifferent from other plotly platform, plot.R is free and open source.\n\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe code chunk below plots an interactive scatter plot by using plot_ly().\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\nThe output:\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE) #<<\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nChanging colour pallete: plot_ly() method\nIn the code chunk below, colors argument is used to change the default colour palette to ColorBrewel colour palette.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = \"Set1\") #<<\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nCustomising colour scheme: plot_ly() method\nIn the code chunk below, a customised colour scheme is created. Then, colors argument is used to change the default colour palette to the customised colour scheme.\n\npal <- c(\"red\", \"purple\", \"blue\", \"green\") #<<\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE, \n        colors = pal) #<<\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nCustomising tooltip: plot_ly() method\nIn the code chunk below, text argument is used to change the default tooltip.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     #<<\n                      \"<br>Class:\", CLASS),  #<<\n        color = ~RACE, \n        colors = \"Set1\")\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nWorking with layout: plot_ly() method\nIn the code chunk below, layout argument is used to change the default tooltip.\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS,\n        text = ~paste(\"Student ID:\", ID,     \n                      \"<br>Class:\", CLASS),  \n        color = ~RACE, \n        colors = \"Set1\") %>%\n  layout(title = 'English Score versus Maths Score ', #<<\n         xaxis = list(range = c(0, 100)),             #<<\n         yaxis = list(range = c(0, 100)))             #<<\n\nTo learn more about layout, visit this link.\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #<<\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\n\n\n\nCoordinated Multiple Views with plotly\nCode chunk below plots two scatterplots and places them next to each other side-by-side by using subplot() of plotly package.\n\np1 <- ggplot(data=exam_data, \n              aes(x = MATHS,\n                  y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),            #<<\n        ggplotly(p2))            #<<\n\nThe side-by-side scatterplots.\n\n\n\n\n\n\nNotice that these two scatter plots are not linked.\n\n\nCoordinated Multiple Views with plotly\nTo create a coordinated scatterplots, highlight_key() of plotly package is used.\n\nd <- highlight_key(exam_data)  #<<\np1 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 <- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---crosstalk-methods",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\n\nLinked brushing: crosstalk method\n\n\nSetting the `off` event (i.e., 'plotly_deselect') to match the `on` event (i.e., 'plotly_selected'). You can change this default via the `highlight()` function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd <- highlight_key(exam_data) \np <- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg <- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#animated-data-visualisation-gganimate-methods",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nGetting started\nAdd the following packages in the packages list:\n\ngganimate: An ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\n\ncol <- c(\"Country\", \"Continent\")\nglobalPop <- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %>%\n  mutate_each_(funs(factor(.)), col) %>%\n  mutate(Year = as.integer(Year))\n\nWarning: `mutate_each_()` was deprecated in dplyr 0.7.0.\nℹ Please use `across()` instead.\n\n\nWarning: `funs()` was deprecated in dplyr 0.8.0.\nℹ Please use a list of either functions or lambdas:\n\n# Simple named list: list(mean = mean, median = median)\n\n# Auto named with `tibble::lst()`: tibble::lst(mean, median)\n\n# Using lambdas list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n\n\n{.pullout-note} Things to learn from the code chunk above:\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       #<<\n  ease_aes('linear')            #<<\n\nThe animated bubble chart"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#visualising-large-data-interactively",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#visualising-large-data-interactively",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Visualising Large Data Interactively",
    "text": "Visualising Large Data Interactively\nIn this hands-on exercise you will learn how to visualise large data by using packed bar methods. For the purpose of this hands-on exercise, two data sets will be used. They are:\n\nGDP.csv provides GDP, GDP per capita and GDP PPP data for world countries from 2000 to 2020. The data was extracted from World Development Indicators Database of World Bank.\nWorldCountry.csv provides a list of country names and the continent they belong to extracted from Statistics Times.\nWrite a code chunk to import both data sets by using read_csv() of readr package.\n\nThe solution:\n\nGDP <- read_csv(\"data/GDP.csv\")\n\nRows: 648 Columns: 25\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (25): Country Name, Country Code, Series Name, Series Code, 2000, 2001, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nWorldCountry <- read_csv(\"data/WorldCountry.csv\")\n\nRows: 250 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Country or Area, ISO-alpha3 Code, Region 1, Region 2, Continent\ndbl (2): No, M49 Code\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote: It is always a good practice to check the data structure and examine data values in RStudio.\n\nData preparetion\nBefore programming the data visualisation, it is important for us to reshape, wrangle and transform the raw data to meet the data visualisation need.\nCode chunk below performs following tasks:\n\nmutate() of dplyr package is used to convert all values in the 202 field into numeric data type.\nselect() of dplyr package is used to extract column 1 to 3 and Values field.\npivot_wider() of tidyr package is used to split the values in Series Name field into columns.\nleft_join() of dplyr package is used to perform a left-join by using Country Code of GDP_selected and ISO-alpha3 Code of WorldCountry tibble data tables as unique identifier.\n\n\nGDP_selected <- GDP %>%\n  mutate(Values = as.numeric(`2020`)) %>%\n  select(1:3, Values) %>%\n  pivot_wider(names_from = `Series Name`,\n              values_from = `Values`) %>%\n  left_join(y=WorldCountry, by = c(\"Country Code\" = \"ISO-alpha3 Code\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Values = as.numeric(`2020`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\nIntroducing packed bar method\n\npacked bar is a relatively new data visualisation method introduced by Xan Gregg from JMP.\n\nIt aims to support the need of visualising skewed data over hundreds of categories.\n\nThe idea is to support the Focus+Context data visualization principle.\nVisit this JMP Blog to learn more about the design principles of packed bar.\n\n\n\n\nData Preparation\nAs usual, we need to prepare the data before building the packed bar. Prepare the data by using the code chunk below.\n\nGDP_selected <- GDP %>%\n  mutate(GDP = as.numeric(`2020`)) %>%\n  filter(`Series Name` == \"GDP (current US$)\") %>%\n  select(1:2, GDP) %>%\n  na.omit()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `GDP = as.numeric(`2020`)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\n\n\nThing to learn from the code chunk above\n\nna.omit() is used to exclude rows with missing values. This is because rPackedBar package does not support missing values.\n\n\n\n\nBuilding a packed bar by using rPackedBar package.\nIn the code chunk below, plotly_packed_bar() of rPackedBar package is used to create an interactive packed bar.\n\np = plotly_packed_bar(\n  input_data = GDP_selected,\n  label_column = \"Country Name\",\n  value_column = \"GDP\",\n  number_rows = 10,\n  plot_title = \"Top 10 countries by GDP, 2020\",\n  xaxis_label = \"GDP (US$)\",\n  hover_label = \"GDP\",\n  min_label_width = 0.018,\n  color_bar_color = \"#00aced\",\n  label_color = \"white\")\nplotly::config(p, displayModeBar = FALSE)\n\n\nRead this Vignettes and the user guide to learn more about the package.\n\nThe output packed bar:\n\n\nWarning: `line.width` does not currently support multiple values.\n\nWarning: `line.width` does not currently support multiple values."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#reference",
    "href": "hands-on_ex/Hands-on_Ex03/Hands-on_Ex03-Programming Interactive Visualisation.html#reference",
    "title": "Hands-on Exercise 3: Programming Interactive Data Visualisation with R",
    "section": "Reference",
    "text": "Reference\n\nggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\n\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\nplotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels\n\n\n\nPacked Bar\nrPackedBar: Packed Bar Charts with ‘plotly’\n\nVisualizing Twitter Data with a Packed Barchart"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "",
    "text": "Funnel plot is a specially designed data visualisation for conducting unbiased comparison between outlets, stores or business entities. By the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting funnel plots by using funnelPlotR package,\nplotting static funnel plot by using ggplot2 package, and\nplotting interactive funnel plot by using both plotly R and ggplot2 packages."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#installing-and-launching-r-packages",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#installing-and-launching-r-packages",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "Installing and Launching R Packages",
    "text": "Installing and Launching R Packages\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#importing-data",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#importing-data",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "Importing Data",
    "text": "Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSub-district ID\nCity\nDistrict\nSub-district\nPositive\nRecovered\nDeath\n\n\n\n\n3172051003\nJAKARTA UTARA\nPADEMANGAN\nANCOL\n1776\n1691\n26\n\n\n3173041007\nJAKARTA BARAT\nTAMBORA\nANGKE\n1783\n1720\n29\n\n\n3175041005\nJAKARTA TIMUR\nKRAMAT JATI\nBALE KAMBANG\n2049\n1964\n31\n\n\n3175031003\nJAKARTA TIMUR\nJATINEGARA\nBALI MESTER\n827\n797\n13\n\n\n3175101006\nJAKARTA TIMUR\nCIPAYUNG\nBAMBU APUS\n2866\n2792\n27\n\n\n3174031002\nJAKARTA SELATAN\nMAMPANG PRAPATAN\nBANGKA\n1828\n1757\n26"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#funnelplotr-methods",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#funnelplotr-methods",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "FunnelPlotR methods",
    "text": "FunnelPlotR methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\nFunnelPlotR methods: The basic plot\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution.\n\n\n\nFunnelPlotR methods: Makeover 1\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",     #<<\n  xrange = c(0, 6500),  #<<\n  yrange = c(0, 0.05)   #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above. + data_type argument is used to change from default “SR” to “PR” (i.e. proportions). + xrange and yrange are used to set the range of x-axis and y-axis\n\n\nFunnelPlotR methods: Makeover 2\nThe code chunk below plots a funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#funnel-plot-for-fair-visual-comparison-ggplot2-methods",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "Funnel Plot for Fair Visual Comparison: ggplot2 methods",
    "text": "Funnel Plot for Fair Visual Comparison: ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\nComputing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\n\n\nCalculate lower and upper limits for 95% and 99.9% CI\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\n\n\nPlotting a static funnel plot\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np\n\n\n\n\n\n\nInteractive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#references",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Funnel_Plot.html#references",
    "title": "Hands-on Exercise 4: Building Funnel Plot with R",
    "section": "References",
    "text": "References\n\nfunnelPlotR package.\nFunnel Plots for Indirectly-standardised ratios.\nChanging funnel plot options\nggplot2 package."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#visual-statistical-analysis-with-ggstatsplot",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#visual-statistical-analysis-with-ggstatsplot",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "Visual Statistical Analysis with ggstatsplot",
    "text": "Visual Statistical Analysis with ggstatsplot\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default.\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#getting-started",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started\n\nInstalling and launching R packages\nIn this exercise, ggstatsplot and tidyverse will be used.\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\nImporting data\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\nImporting Exam.csv data by using appropriate tidyverse package.\n\n\n\n\n# A tibble: 322 × 7\n   ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n   <chr>      <chr> <chr>  <chr>     <dbl> <dbl>   <dbl>\n 1 Student321 3I    Male   Malay        21     9      15\n 2 Student305 3I    Female Malay        24    22      16\n 3 Student289 3H    Male   Chinese      26    16      16\n 4 Student227 3F    Male   Chinese      27    77      31\n 5 Student318 3I    Male   Malay        27    11      25\n 6 Student306 3I    Female Malay        31    16      16\n 7 Student313 3I    Male   Chinese      31    21      25\n 8 Student316 3I    Male   Malay        31    18      27\n 9 Student312 3I    Male   Malay        33    19      15\n10 Student297 3H    Male   Indian       34    49      37\n# … with 312 more rows\n\n\n\n\nOne-sample test: gghistostats() method\nIn the code chunk below, gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nUnpacking the Bayes Factor\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\nHow to interpret Bayes Factor\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\nTwo-sample mean test: ggbetweenstats()\nIn the code chunk below, ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\nOneway ANOVA Test: ggbetweenstats() method\nIn the code chunk below, ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n“ns” → only non-significant\n“s” → only significant\n“all” → everything\n\n\nggbetweenstats - Summary of tests\n\n\n\n\n\n\nSignificant Test of Correlation: ggscatterstats()\nIn the code chunk below, ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\nSignificant Test of Association (Depedence) : ggbarstats() methods\nIn the code chunk below, the Maths scores is binned into a 4-class variable by using cut().\n\nexam1 <- exam %>% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nIn this code chunk below ggbarstats() is used to build a visual for Significant Test of Association\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#visualising-models",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#visualising-models",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "Visualising Models",
    "text": "Visualising Models\nIn this section, you will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#getting-started-1",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#getting-started-1",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#installing-and-loading-the-required-libraries",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual Statistical Analysis.html#installing-and-loading-the-required-libraries",
    "title": "Hands-on Exercise 4: Visual Statistical Analysis",
    "section": "Installing and loading the required libraries",
    "text": "Installing and loading the required libraries\n\n\n\n\n\n\nDo-It-Yourself\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\n\n\nImporting Excel file: readxl methods\nIn the code chunk below, read_xls() of readxl package is used to import the data worksheet of ToyotaCorolla.xls workbook into R.\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\nNotice that the output object car_resale is a tibble data frame.\n\n\nMultiple Regression Model using lm()\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: checking for multicolinearity:\nIn the code chunk, check_collinearity() of performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\n\nModel Diagnostic: checking normality assumption\nIn the code chunk, check_normality() of performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Check model for homogeneity of variances\nIn the code chunk, check_heteroscedasticity() of performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nWe can also perform the complete by using check_model().\n\ncheck_model(model1)\n\n\n\n\n\n\nVisualising Regression Parameters: see methods\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\nVisualising Regression Parameters: ggcoefstats() methods\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html",
    "title": "Hands-on Exercise 4: Visualising Uncertainty",
    "section": "",
    "text": "In this hands-on exercise"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualizing-the-uncertainty-of-point-estimates",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualizing-the-uncertainty-of-point-estimates",
    "title": "Hands-on Exercise 4: Visualising Uncertainty",
    "section": "Visualizing the uncertainty of point estimates",
    "text": "Visualizing the uncertainty of point estimates\n\nA point estimate is a single number, such as a mean.\nUncertainty is expressed as standard error, confidence interval, or credible interval\nImportant:\n\nDon’t confuse the uncertainty of a point estimate with the variation in the sample\n\n\n\npacman::p_load(tidyverse, plotly, crosstalk, DT, ggdist, gganimate)\n\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below performs the followings:\n\ngroup the observation by RACE,\ncomputes the count of observations, mean, standard deviation and standard error of Maths by RACE, and\nsave the output as a tibble data table called my_sum.\n\n\nmy_sum <- exam %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\nNote: For the mathematical explanation, please refer to Slide 20 of Lesson 4.\nNext, the code chunk below will\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\nThe code chunk below is used to reveal the standard error of mean maths score by race.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggplot2 methods\n\n\n\n\n\n\nYour turn\n\n\n\nPlot the 95% confidence interval of mean maths score by race. The error bars should be sorted by the average maths scores.\n\n\n\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates with interactive error bars\n\n\n\n\n\n\nYour turn\n\n\n\nPlot interactive error bars for the 99% confidence interval of mean maths score by race."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-ggdist-package",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-ggdist-package",
    "title": "Hands-on Exercise 4: Visualising Uncertainty",
    "section": "Visualising Uncertainty: ggdist package",
    "text": "Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_pointinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +   #<<\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\nexam %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\n\n\n\n\n\n\nYour turn\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\n\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail.\n\n\nVisualizing the uncertainty of point estimates: ggdist methods\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\n\n\n\nGentle advice: This function comes with many arguments, students are advised to read the syntax reference for more detail."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands-on Exercise 4: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\nStep 1: Installing ungeviz package\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\nNote: You only need to perform this step once.\nStep 2: Launch the application in R\n\nlibrary(ungeviz)\n\n\nggplot(data = exam, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "href": "hands-on_ex/Hands-on_Ex04/Hands-on_Ex04-Visual_Uncertainty.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops-1",
    "title": "Hands-on Exercise 4: Visualising Uncertainty",
    "section": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nggplot(data = exam, \n       (aes(x = factor(RACE), \n            y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, \n    width = 0.05), \n    size = 0.4, \n    color = \"#0072B2\", \n    alpha = 1/2) +\n  geom_hpline(data = sampler(25, \n                             group = RACE), \n              height = 0.6, \n              color = \"#D55E00\") +\n  theme_bw() + \n  transition_states(.draw, 1, 3)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "",
    "text": "Correlation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#importing-data",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#importing-data",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Importing Data",
    "text": "Importing Data\nFirst, let us import the data into R by using read_csv() of readr package.\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nNotice that beside quality and type, the rest of the variables are numerical and continuous data type."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#building-a-basic-correlation-matrix",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#building-a-basic-correlation-matrix",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Building a basic correlation matrix",
    "text": "Building a basic correlation matrix\nFigure below shows the scatter plot matrix of Wine Quality Data. It is a 11 by 11 matrix.\n\npairs(wine[,1:11])\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\npairs(wine[,2:12])"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#drawing-the-lower-corner",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#drawing-the-lower-corner",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Drawing the lower corner",
    "text": "Drawing the lower corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chun below.\n\npairs(wine[,2:12], lower.panel = NULL)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#including-with-correlation-coefficients",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#including-with-correlation-coefficients",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Including with correlation coefficients",
    "text": "Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\npanel.cor <- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr <- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr <- abs(cor(x, y, use=\"complete.obs\"))\ntxt <- format(c(r, 0.123456789), digits=digits)[1]\ntxt <- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#the-basic-plot",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#the-basic-plot",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "The basic plot",
    "text": "The basic plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#building-multiple-plots",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#building-multiple-plots",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Building multiple plots",
    "text": "Building multiple plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#getting-started-with-corrplot",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#getting-started-with-corrplot",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Getting started with corrplot",
    "text": "Getting started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\nwine.cor <- cor(wine[, 1:11])\n\nNext, corrplot() is used to plot the corrgram by using all the default setting as shown in the code chunk below.\n\ncorrplot(wine.cor)\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-visual-geometrics",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-visual-geometrics",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Working with visual geometrics",
    "text": "Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\nFeel free to change the method argument to other supported visual geometrics."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-layout",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-layout",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Working with layout",
    "text": "Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-mixed-layout",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#working-with-mixed-layout",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Working with mixed layout",
    "text": "Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#combining-corrgram-with-the-significant-test",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#combining-corrgram-with-the-significant-test",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Combining corrgram with the significant test",
    "text": "Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\n\n\n\n\n\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#reorder-a-corrgram",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#reorder-a-corrgram",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "Reorder a corrgram",
    "text": "Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\nReordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#r-packages",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Corrgram.html#r-packages",
    "title": "Hands-on Exercise 5: Visualising Correlation Matrices",
    "section": "R packages",
    "text": "R packages\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "",
    "text": "Heatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#importing-the-data-set",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#importing-the-data-set",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Importing the data set",
    "text": "Importing the data set\nIn the code chunk below, read_csv() of readr is used to import WHData-2018.csv into R and parsed it into tibble R data frame format.\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nThe output tibbled data frame is called wh."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#preparing-the-data",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#preparing-the-data",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Preparing the data",
    "text": "Preparing the data\nNext, we need to change the rows by country name instead of row number by using the code chunk below\n\nrow.names(wh) <- wh$Country\n\nNotice that the row number has been replaced into the country name."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#transforming-the-data-frame-into-a-matrix",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#transforming-the-data-frame-into-a-matrix",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Transforming the data frame into a matrix",
    "text": "Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#heatmap-of-r-stats",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#heatmap-of-r-stats",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "heatmap() of R Stats",
    "text": "heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#working-with-heatmaply",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#working-with-heatmaply",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Working with heatmaply",
    "text": "Working with heatmaply\n\nheatmaply(mtcars)\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#data-trasformation",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#data-trasformation",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Data trasformation",
    "text": "Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\nScaling method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\n\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\nNormalising method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\nPercentising method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#clustering-algorithm",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#clustering-algorithm",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Clustering algorithm",
    "text": "Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\nManual approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\nStatistical approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#seriation",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#seriation",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "5.4 Seriation",
    "text": "5.4 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#working-with-colour-palettes",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#working-with-colour-palettes",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "Working with colour palettes",
    "text": "Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#the-finishing-touch",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Heatmap.html#the-finishing-touch",
    "title": "Hands-on Exercise 5: Building Heatmap for Visualising and Analysing Multivariate Data",
    "section": "The finishing touch",
    "text": "The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "",
    "text": "Parallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package.\n\n\n\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\n\n\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nIn the code chunk below, read_csv() of readr package is used to import WHData-2018.csv into R and save it into a tibble data frame object called wh.\n\nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#plotting-a-simple-parallel-coordinates",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#plotting-a-simple-parallel-coordinates",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Plotting a simple parallel coordinates",
    "text": "Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#plotting-a-parallel-coordinates-with-boxplot",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#plotting-a-parallel-coordinates-with-boxplot",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Plotting a parallel coordinates with boxplot",
    "text": "Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\n\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#parallel-coordinates-with-facet",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#parallel-coordinates-with-facet",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Parallel coordinates with facet",
    "text": "Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#rotating-x-axis-text-label",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#rotating-x-axis-text-label",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Rotating x-axis text label",
    "text": "Rotating x-axis text label\nTo make the x-axis text label easy to read, let us rotate the labels by 30 degrees. We can rotate axis text labels using theme() function in ggplot2 as shown in the code chunk below\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#adjusting-the-rotated-x-axis-text-label",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#adjusting-the-rotated-x-axis-text-label",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Adjusting the rotated x-axis text label",
    "text": "Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#the-basic-plot",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#the-basic-plot",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "The basic plot",
    "text": "The basic plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#rotate-axis-label",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#rotate-axis-label",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Rotate axis label",
    "text": "Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#changing-the-colour-scheme",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#changing-the-colour-scheme",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Changing the colour scheme",
    "text": "Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunl below.\n\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#parallel-coordinates-plot-with-histogram",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-pcp.html#parallel-coordinates-plot-with-histogram",
    "title": "Hands-on Exercise 5: Creating Parallel Coordinates Plots with R",
    "section": "Parallel coordinates plot with histogram",
    "text": "Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#the-data",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#the-data",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "The data",
    "text": "The data\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#importing-data",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#importing-data",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "Importing Data",
    "text": "Importing Data\nTo important respopagsex2000to2018_tidy.csv into R, read_csv() function of readr package will be used.\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#preparing-the-data",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#preparing-the-data",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "Preparing the Data",
    "text": "Preparing the Data\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  pivot_wider(names_from = AG, \n              values_from = Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#plotting-a-static-ternary-diagram",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#plotting-a-static-ternary-diagram",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "Plotting a static ternary diagram",
    "text": "Plotting a static ternary diagram\nUse ggtern() function of ggtern package to create a simple ternary plot.\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#plotting-an-interative-ternary-diagram",
    "href": "hands-on_ex/Hands-on_Ex05/Hands-on_Ex05-Ternary.html#plotting-an-interative-ternary-diagram",
    "title": "Hands-on Exercise 5: Building Ternary Plot with R",
    "section": "Plotting an interative ternary diagram",
    "text": "Plotting an interative ternary diagram\nThe code below create an interactive ternary plot using plot_ly() function of Plotly R.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n\n\n\n\n\n\nDo It Yourself\n\n\n\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\n\n\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608 AY2022-23 Jan Term",
    "section": "",
    "text": "Welcome to the home page for ISSS608 Visual Analytics and Applications. All course materials will be posted on this site.\nInstructor: Dr. Kam Tin Seong, Associate Professor of Information Systems (Practice)\nLesson (day/time): Saturday 12:00pm to 3:15pm\nVenue: Refer to Lesson Plan\nConsultation booking link.\nVirtual Meeting Room: Zoom"
  },
  {
    "objectID": "index.html#other-important-information",
    "href": "index.html#other-important-information",
    "title": "ISSS608 AY2022-23 Jan Term",
    "section": "Other Important Information",
    "text": "Other Important Information\n\nAcademic Integrity:\nAll acts of academic dishonesty (including, but not limited to, plagiarism, cheating, fabrication, facilitation of acts of academic dishonesty by others, unauthorized possession of exam questions, or tampering with the academic work of other students) are serious offences. All work (whether oral or written) submitted for purposes of assessment must be the student’s own work. Penalties for violation of the policy range from zero marks for the component assessment to expulsion, depending on the nature of the offense. When in doubt, students should consult the instructors of the course. Details on the SMU Code of Academic Integrity may be accessed at http://www.smuscd.org/resources.html\n\n\nHandling of Course Materials:\nCourse materials obtained during your course of study at SMU are meant for personal use only, namely, for the purposes of studying and research. You are strictly not permitted to make copies of or print additional copies or distribute such copies of the course materials or any parts thereof, for commercial gain or exchange. For example, offering such materials on the Internet through CourseHero, Carousell and the like, is strictly prohibited.\nThe selling of these materials and/or any copies thereof are strictly prohibited under Singapore copyright laws. Printed materials and electronic materials are both protected by copyright laws. All students are subject to Singapore copyright laws and must strictly adhere to SMU’s procedures and requirements relating to copyright.\nPlease also note that for some materials, the publishers may specifically state that each copy is for the personal use of one individual only and no further reprographic reproduction is allowed, including for personal use. These restrictions are spelt out clearly on these specific sets of resources and students are required to adhere to these rules.\nStudents who infringe any of the aforesaid rules, laws and requirements shall be liable to disciplinary action by SMU. In addition, such students may also leave themselves open to suits by copyright owners who are entitled to take legal action against persons who infringe their copyright.\nWe strongly urge all students to respect the copyright laws and abide by SMU’s procedures and requirements relating to copyright.\n\n\nAccessibility and Accommodations:\nSMU strives to make learning experiences accessible for all. If you anticipate or experience physical or academic barriers due to disability, please let the instructor know immediately. You are also welcome to contact the university’s disability support team if you have questions or concerns about academic accommodations:included@smu.edu.sg\nPlease be aware that the accessible tables in our seminar room should remain available for students who require them. Emergency Preparedness for Teaching and Learning (EPTL): As part of emergency preparedness, Instructors may conduct lessons online via the WebEx platform during the term, to prepare students for online learning. During an actual emergency, students will be notified to access the WebEx platform for their online lessons. The class schedule will mirror the current face-to-face class timetable unless otherwise stated."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nThe World is full of charts that lie!\n\nWe need to get smarter about visual information\n\nIt is very common you see infographic of this kind appears on our daily newspaper. At a first glance, it seems making a lot of sense. But, when we try to take a closer look at the text and graph, you will notice that there are at least two major issues, one is related to truthfulness of the data visualisation and the second one is related to its clarity aspect. For example, the x-axis is showing quarterly time interval. But, the second sentence talks about “For the first half this year, Nodx fell 4.5 per cent compared with the same period last year.” which is not inline with what was shown on the x-axis. Furthermore, the values on the y-axis are in per cent. Hence the correct term should be percentage point instead of per cent because we are comparing the differences between two percentages.\nThis is what motivate me to design this course. This course is not about using Tableau or R to create beautiful data visualisation only. More importantly, it aims to embark you the skills of getting smarter when reading data visualisation. From today onwards, I would like to encourage you to take a good look at every data visualisation you come across and carefully evaluate them not only from their aestheticness only but also their clarity."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-1",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-1",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nJunk charts are good for advertising but not for understanding.\n\n\nIn business, it is very common we see marketing data visualisation similar to the one on this slide. I call this Junk Chart. As we know, junk foods are very tempting but not healthy. Similar, Junk Charts tends to be very appealing but they are not useful to gain data understanding. For example, it is not possible for us to do an effective comparison between global sales revenue and reinvestment in R&D because of the inappropriate use of 3d bar chart.\nThe important take away from this slide is to avoid creating eye candy data visualisation. We should create data visualisation that are functional instead."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-2",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-2",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nData rich, information poor\n\nSource: Big Data Ocean\n\nIn this big data age, data analyst tends to flooded with large amount of data. Before she/he can build any effective model by using advanced AI/ML techniques, she/he need to first understand the data and data visualisation is one of the most commonly used approach."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-3",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-3",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nThe World is buried in data,\nJust SHOW me the number\n\n\nUnfortunately, Up until very recently, data analysts tend to depend on spreadsheet to visualisation these large volume of data. No doubt, spreadsheet is an effective tool for organising, tabulating and processing data but it not appropriate for creating graph that are enlightening.\nMany of you might not agree with me. Let me use the next slide to explain my point."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-4",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-4",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\n\n\nSpreadsheet: A great hammer but lousy screwdriver\n\n\nVisual analytics come to the rescue\n\n\n\n\nAs all of you will notice that the data visualisation on the left were created using Microsoft Excel charting function. It shows the results of five models output. Unfortunately, it is not easy to compare the differences between them. This is partly because the value range of their y-axis are not the same. Further more by stitching the line graph top down and next jump to the right fail for support effective comparison.\nThe data visualisation on the right is a makeover version. It was created using the trellis method of JMP Pro. In this case, all line graphs maintain the same value range. As a result, the data visualisation reveals the differences between the five models clearly.\nAlso, by arranging the model results from left to right according to their calibration, allows us to compare the performance of each model effectively."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-5",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-5",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nWhen statistics failed!\n\n\n\n\n\n\n\nData analysis without data visualisation is no data analysis\n\nAs a data analyst, we tend to use statistics to describe data distribution. However, these might not be enough without data visualisation.\nThis slide shows a data sets of four groups of observation. When their summary statistics such as mean and standard deviation were computed. It is interesting to note that they are all having the similar values. In fact, even the correlation coefficient and best fit line equations are similar."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-6",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-6",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nAnalytical graphics reveal the truth\n\n\nHowever, when we plot these data by using scatter plot method as shown on the slide, it is interesting to note that they reveal very different patterns."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-7",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-7",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nIs there a place for Visual Analytics in knowledge discovery?\n\n\nThe important take away from this example is that it is always useful to use data visualisation to complement data modelling. As shown in the figure. In a knowledge discovery process, visual analytics provide data analysts useful understanding of the data. These understanding can be used to support effective model building.\nData visualisation also should be used to reveal modelling results. Furthermore, by using data visualisation to communicate complex modelling results to senior management, in general, are more effectively than showing them complex equations."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-8",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-8",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nOpen data need to be unlocked!\n\nVisit the link\n\nRecently, there is an increasing available of open source data from the public sector. However, to put these data into good use for informed decision making, we also need appropriate analytics tools. By and large, the COS analytics software are too costly and beyond the reach of SME and casual users. On the other hand, free and open source analytical APIs tend to require certain level of proficiency in programming which is not a common skill posses by business analysts."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-9",
    "href": "lesson/Lesson01/Lesson01-VAA.html#motivation-of-visual-analytics-9",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Motivation of Visual Analytics",
    "text": "Motivation of Visual Analytics\nDemocratising Data and Analytics with Visually-driven Web Apps\n\nVisit the link\n\nIn view of this, I strongly belief that it is important for our MITB (Analytics) students master the skill of building visually-driven web-based data analytics applications to democratise data and analytics.\nThe link on this slide shows an example of a visual analytics web application designed using R packages and Shiny, a framework and API for building web application in R.\nThe advantage of this approach is that it allows users to perform the analysis without having to learn programming. Furthermore, data visualisation are used extensively in the modelling process. For visual Analytics applications developers, their only need learn one programming languasge which is R instead of a collection of web development languages such as html, javascripts and css."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\n\n\nVisual Analytics is the craft of analytical reasoning supported by:\n\nData Science and Analytics\nData Visualisation\nHuman-Computing-Interaction (HCI)\nInterface Design\nVisual Storytelling\n\n\n\n\n\nThe marriage of data analytics and visualizations\n\nThis slide aims to explain the building block of Visual Analytics. It is the craft of ………….."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-1",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-1",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nScience of Visual Analytics"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-2",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-2",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nAims of Visual Analytics\n\n\n\n\n\n\nAlthough visual analytics comprises of many scientific disciplines. It is important to note that the goal of a visual analytics is to help data analyst to discover the unexpected from data effectively."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-3",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-3",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nVisual Data Sense-making\nVisual Analytics’ greatest strength is its use for sense-making.\n\n\n\n\n\n\n\n\nDifferent from statistical analysis, machine learning and AI, Visual analytics emphasise on visual sensing rather than mathematics and statistical skills."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-4",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-4",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nVisual Analytics Framework\n\n\nAs a results, when we do Visual Analytics, we need to immerse our in a highly interactive environment. Our eyes will be used to detect the unusual visual pattern with the help of appropriate data visualisation method(s). Our brain will then interpret and synthesise the visual information and send impulses to our hand to change the view in search of new visual patterns"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-5",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-5",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nVisual Analytics require a shift of mindset\n\n\nTraditionally, statistical graphics are used for visual communication alone. Visual Analytics require a major paradigm shift from visual communication to visual thinking. Data Visualisation or statistical graphics should be used to support data exploration and analysis instead of visual communication alone. Having said that, this does not mean that visual communication is no longer important. Instead, the new paradigm shift requires us to give equal focus on both visual thinking and visual communication."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-6",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-6",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nLearning from the history of Visual Analytics\nCommercial and Political Atlas by William Playfair (22 September 1759 – 11 February 1823)\n\n\nSpeaking about Visual Analytics, there are a lot we can learn from history. The line graph on the slide is a good example. This is a trade balance line graph prepared by William Playfair in 1786. You probably have identify this chart as a common line graph. The horizontal axis is years, the vertical axis measures the volume of imports and export. When you take a good look at the graph, you will be very impressed by conscious effort given by the author to shade the space between the import and export lines. When the trade balance was against England, the area was shared in red and when the trade balance was in favour of England, the area was shaded in brown. With the advancement of graph drawing tools, sadly to say, we hardly see this carefully crafted line graph been used."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-7",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-7",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nLearning from the history of Visual Analytics\nCholera and the Pump on Broad Street(John Snow, 1854).\n\n\nThe map on this figure is the ground breaking used of map in medical science. It was one of the many versions prepared by John Snow and published in 1854. If you take a closer look at the map, you will notice that it is not a normal dot map we commonly prepared using Google Map or other data visualisation toolkits like Tableau or PowerBI. In the map, cholera cases are highlighted in black, showing the clusters of cholera cases (indicated by stacked rectangles) in the London epidemic of 1854. The map marks an important part of the development of epidemiology as a field, and of disease mapping as a whole."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-8",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-8",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nLearning from the history of Visual Analytics\nFlorence Nightingale: The compassionate statistician(12 May 1820 – 13 August 1910)\n\n\nThe third example is the famous rose diagram or coxcombs prepared by Florence Nightingale. Many of us know Florence as The Mother of Nursing, but she was also a statistician, and reformer. If we look at the rose diagram, we can see that the area of each coloured wedge, measured from the centre, is in proportion to the statistic it represents. The blue outer wedges represent the deaths from contagious diseases, such as cholera and typhus. The central red wedges show the deaths from wounds. The black wedges in between represent deaths from all other causes. If this rate had continued, and troops had not been replaced frequently, then disease alone would have killed the entire British Army in the Crimea. Nightingale’s graph not only dramatised the extent of the needless deaths among the soldiers during the Crimean War, but it was used as a tool to persuade Victorial government and medical profession that deaths were preventable if sanitation reforms were implemented in military and civilian hospitals."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-9",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-9",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nLearning from the history of Visual Analytics\nPlot of Napoleon’s ill-fated Russian campaign of 1812-1813 (Charles Joseph Minard,1861)\n\n\nThe last example is the famous Charles Joseph Minard’s Napoleon’s Russian campaign chart. At the first glance, it resemble the flow map but the map actually reveal more information than a common flow map. The illustration depicts Napoleon’s army departing the Polish-Russian border. A thick band illustrates the size of his army at specific geographic points during their advance and retreat. It displays six types of data in two dimensions: the number of Napoleon’s troops; the distance traveled; temperature; latitude and longitude; direction of travel; and location relative to specific dates without making mention of Napoleon; Minard’s interest lay with the travails and sacrifices of the soldiers. This type of band graph for illustration of flows was later called a Sankey diagram, although Matthew Henry Phineas Riall Sankey (9 November 1853 – 3 October 1926) used this visualisation 30 years later and only for thematic energy flow. Interestingly, If you take a closer look at the lower center of the graph, you will notice that the term Tableau Graphique was used.\nThe important learning lesson from these four historical data visualisation is that in order to design a functional and yet enlightening data visualisation, we need to master the science and arts of data visualisation design instead of using default graphing functions of modern data visualisation toolkit. Just like writing, by knowing how to use MS Word, you will not be able to become a great editor."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-10",
    "href": "lesson/Lesson01/Lesson01-VAA.html#what-is-visual-analytics-10",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "What is Visual Analytics?",
    "text": "What is Visual Analytics?\nVisual Analytics must be Reproducible\n\n\n\n\nFor every result, keep track of how it was produced.\nAvoid manual data manipulation steps.\nArchive the excat versions of all external programmes used.\nVersion control all custom scripts.\nRecord all intermediate results, when possible in standard formats.\nFor analysis that include randomness, note underlying random seeds.\nAlways store raw data behind plots.\nGenerate hierarchical analysis output, allowing layers of increasing detail to be inspected.\n\n\n\nConnect textual statements to underlying results.\nProvide public access to scripts, runs, and results.\n\n\n\n\n\n\nReference: Ten Simple Rules for Reproducible Computational Research\n\n\nOne of the biggest challenge of visual analytics is reproducibility. In this course, you will learn the skill of building reproducible data visualisation by using RMarkdown in order to ensure that all the steps and codes used to build the data visualisation are comprehensively documented and can be reproduced by others."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#data-visualisation-toolkits",
    "href": "lesson/Lesson01/Lesson01-VAA.html#data-visualisation-toolkits",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Data Visualisation Toolkits",
    "text": "Data Visualisation Toolkits\n\nCommercial-off-the-shelf\n\nVisual analytics tookit such as Tableau, JMP, PowerBI, Qlik Sense/View & TIBCO SpotFire.\nSpecialised data visualisation applications such as TreeMap from Macrofocus\n\nOpen source\n\nSpecialised data visualisation applications such as Gephi\nData visualisation API library such as ggplot2, plotly, and D3.js\n\n\n\nIn general, we can divide the data visualisation toolkit into two main groups namely, Commercial of the shelf also known as COS and open source. A good example of COS data visualisation toolkits are Tableau, Qlik View/Sense."
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#cos-data-visualisualisation-toolkit",
    "href": "lesson/Lesson01/Lesson01-VAA.html#cos-data-visualisualisation-toolkit",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "COS Data Visualisualisation Toolkit",
    "text": "COS Data Visualisualisation Toolkit\nMagic Quadrant for BI and Analytics Platforms"
  },
  {
    "objectID": "lesson/Lesson01/Lesson01-VAA.html#highly-recommended-blogs",
    "href": "lesson/Lesson01/Lesson01-VAA.html#highly-recommended-blogs",
    "title": "Lesson 1 Introduction to Visual Analytics and Applications",
    "section": "Highly recommended blogs",
    "text": "Highly recommended blogs\n\nPerceptual Edge\nJunk Charts\nThe Functional Art\n\n\nThis slide provides you the links to three highly recommended data visualisation blogs. I strongly encourage students to visit bookmark them and visit them often not only during these course but also when you go our to practice."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#what-will-you-learn-from-this-lesson",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#what-will-you-learn-from-this-lesson",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "What will you learn from this lesson?",
    "text": "What will you learn from this lesson?\n\n\nData visualisation design process\nThe Devil is in the data\nHuman perception and information processing\nComponents of a graph\nPrinciples and practical guides for data visualisation design\nData visualisation critics framework\n\n\n\nIn this lesson, I am going to share with you the basic principles and best practices of Data Visualisation Design. The discussion consists of five sections. First, I will provide an overview of data visualisation design process. Next, by using appropriate examples, I will share with you the importance of data selection and preparation in building enlightening graphs. In section three, the principles of visual perception will be introduce. In section four, the practical guides of data visualisation design will be discussed. Lastly, a framework for evaluating and criticising data visualisation design will be introduced."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#building-block-of-visual-analytics",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#building-block-of-visual-analytics",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Building Block of Visual Analytics",
    "text": "Building Block of Visual Analytics\n\n\nThis slide shows the building block of visual analytics. Today, we will focus our attention on the lower left corner of the building block, namely Visual Perception."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#datavis-design-process",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#datavis-design-process",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "DataVis design process",
    "text": "DataVis design process\n\nStart with a clear message\nSelect the right data\nUse the right visualisations\nExpress and explain\nReview and seek feedback from experts and casual readers\n\n\nIn general, a data visualisation design process consists of five major steps."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#dataviz-design-process-start-with-a-clear-message",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#dataviz-design-process-start-with-a-clear-message",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "DataViz design process: Start with a clear message",
    "text": "DataViz design process: Start with a clear message\n\n\nIn data visualisation design, it is important to be clear and explicit about what you want to achieve. Is it to explore some data, to convey an inferential analysis, to deliver a message, convince an audience, or support a decision? It may be a mixture of these—for example, even seemingly simple exploratory plots should serve some (perhaps implicit) decision (e.g., on how to explore further). Every graph, and, more generally, every communication, must be tailored to its specific purpose."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#the-devil-is-in-the-data",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#the-devil-is-in-the-data",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "The Devil is in the Data",
    "text": "The Devil is in the Data\n\n\nClean and tidy data are needed to build truthful data visualisation. But beside clean and tidy data, there are at least two considerations related to data require our attention."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Graphical Integrity: Show Me the Truth",
    "text": "Graphical Integrity: Show Me the Truth\n\n\nSource: Department of Statistics\n\n\nLet us take a good look at the data visualisation on the slide. Can you spot any graphical integrity issue? Yes, the issue of inconsistent data aggregation. On the figure, the major trading partners are at the country level except EU."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth-1",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth-1",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Graphical Integrity: Show Me the Truth",
    "text": "Graphical Integrity: Show Me the Truth\nSnapshot can be misleading!\n\n\n\n\n\n\n\n\nSource: Cairo, Alberto (2019) How Charts Lie, W.W. Norton & Company, USA. pg 168.\n\n\nDonald Trump liked to claim that the job market was a “disaster” before he was sworn in but recovered right after, and he used charts that cropped the horizontal axis in a convenient place.\nBut if we go back in time and mark the point when Trump became president, we’ll see that there’s no remarkable change in the trajectory and slope of the line. Jobs began recovering in 2010."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth-2",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graphical-integrity-show-me-the-truth-2",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Graphical Integrity: Show Me the Truth",
    "text": "Graphical Integrity: Show Me the Truth\nDo not miss-out what had happened in between."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#human-perception-and-information-processing",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#human-perception-and-information-processing",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Human Perception and Information Processing",
    "text": "Human Perception and Information Processing"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#application-of-pre-attentive-principle-in-data-visualisation-design-1",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#application-of-pre-attentive-principle-in-data-visualisation-design-1",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Application of pre-attentive principle in data visualisation design",
    "text": "Application of pre-attentive principle in data visualisation design\n\n\n\n\n\n\n\n\nIn the data visualisation of the right, bright red is use to show the month running at a lot. This is another example whereby pre-attentive principle is put go used."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#components-of-a-graph",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#components-of-a-graph",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Components of a graph",
    "text": "Components of a graph"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#bertins-semiology-of-graphics",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#bertins-semiology-of-graphics",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Bertin’s Semiology of graphics",
    "text": "Bertin’s Semiology of graphics"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#choosing-the-right-visualisation",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#choosing-the-right-visualisation",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Choosing the Right Visualisation",
    "text": "Choosing the Right Visualisation"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Design principles for effective visual presentation",
    "text": "Design principles for effective visual presentation\n\n\nGuides for Encoding Values in Graph\nJunkCharts\nPractical Guides for Using Colour in Charts\nData-ink"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-2",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-2",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Design principles for effective visual presentation",
    "text": "Design principles for effective visual presentation\n\n\nGuides for Encoding Values in Graph\nChartjunk\nPractical Guides for Using Colour in Charts\nData-ink\n\n\n\nChartjunk refers to all visual elements in charts and graphs that are not necessary to comprehend the information represented on the graph, or that distract the viewer from this information.\nIt was first introduced by Edward Tufte in his 1983 book The Visual Display of Quantitative Information.\nThere is an interesting blog called Junk Charts by Kaiser Fung. The blog link is available on the last slide."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-3",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-3",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Design principles for effective visual presentation",
    "text": "Design principles for effective visual presentation\n\n\nGuides for Encoding Values in Graph\nJunkCharts\nPractical Guides for Using Colour in Charts\nData-ink\n\n\n\nIn this topic, I am going to share with the practical guides for using colour in data visualisation."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-4",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#design-principles-for-effective-visual-presentation-4",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Design principles for effective visual presentation",
    "text": "Design principles for effective visual presentation\n\n\nGuides for Encoding Values in Graph\nJunkCharts\nPractical Guides for Using Colour in Charts\nData-ink"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#data-ink",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#data-ink",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Data-ink",
    "text": "Data-ink\n\n\n\nReduce the non data-ink\n\nRemoved unnecessary non data-ink\nDe-emphasise or regularise the remaining non data-ink\n\nEnhance the data-ink\n\nRemove unnecessary data-ink\nEmphasise the remaining data-ink\n\n\n\n\n\n\n\nThe term, ‘data-ink’, is defined as the total ink on a graph that represents data. Tufte claims that good graphical representations maximize data-ink and erase as much non-data-ink as possible. Thus, he defines the data-ink ratio is the proportion of a graphic’s ink devoted to the non-redundant display of data-information. It should equal to (1 - the proportion of graphics that can be erased without loss of data-information)."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#an-enligthening-data-visualisation-will-be-incomplete-without-a-well-worded-title",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#an-enligthening-data-visualisation-will-be-incomplete-without-a-well-worded-title",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "An enligthening data visualisation will be incomplete without a well worded title",
    "text": "An enligthening data visualisation will be incomplete without a well worded title\n\n\nSource: The truth about weekend working, Financial Times, January 23 2020.\n\nMore example can be found here"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graph-typography",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#graph-typography",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Graph typography",
    "text": "Graph typography\nAvoid using artistic fonts"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#three-bugs-of-charts-interpretation",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#three-bugs-of-charts-interpretation",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Three Bugs of Charts Interpretation",
    "text": "Three Bugs of Charts Interpretation\n\n\nThe Patternicity bug: We detect interating patterns, regardless of whether or not they are real.\nThe Storytelling bug: We immediately come up with a coherent explanation for those patterns.\nThe Confirmation bug: We start seeing all further information we receive, even the one that conflicts with our explanation, in a way that confirmed it. We refuse to give our explanation up, no matter what."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#data-visualization-clarity-or-aesthetics",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#data-visualization-clarity-or-aesthetics",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Data Visualization: Clarity or Aesthetics?",
    "text": "Data Visualization: Clarity or Aesthetics?\n\n\n\n\n\n\n\n\nSource: Data Visualisation: Clarity or Aesthetics"
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#references",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#references",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "References",
    "text": "References\nClaus O. Wilke (2019) Fundamentals of Data Visuaization. O’Reilly, USA.\nFew, Stephen (2012) (2nd edition) Show Me the Numbers: Designing Tables and Graphs to Enlighten, Analytics Press, Oakland, USA\nCairo, Alberto (2019) How Charts Lie, W.W. Norton & Company, USA.\nRobbins, Naomi B. (2005) Creating More Effective Graphs, John Wiley & Sons, New Jersey, USA\nWong, Dona M. (2010) The Wall Street Journal Guide to Information Graphics, W. W. Norton & Company, Inc. New York.\nTufte, Edward (2nd Edition) The Visual Display of Quantitative Information, Graphics Press LLC, Connecticut, USA."
  },
  {
    "objectID": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#highly-recommended-blog",
    "href": "lesson/Lesson02/Lesson02-Designing Graphs to Enlighten.html#highly-recommended-blog",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Highly recommended blog",
    "text": "Highly recommended blog\n\nThe Functional Art\nJunk Charts\nPerceptual Edge\nEagerEyes\nStatistical Graphics and more\nVisualizing data\nVisualizing Economics"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#what-will-you-learn-from-this-lesson",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#what-will-you-learn-from-this-lesson",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "What will you learn from this lesson?",
    "text": "What will you learn from this lesson?\n\n\nTypology of Interactive Techniques\n\nData & view specification\nView Manipulation\nProcess and Provenance\n\nInteractive Design Primitive\nAnimation: Principles and Best Practices"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#building-block-of-visual-analytics",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#building-block-of-visual-analytics",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Building Block of Visual Analytics",
    "text": "Building Block of Visual Analytics"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#taxonomy-of-interactive-dynamics",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#taxonomy-of-interactive-dynamics",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Taxonomy of Interactive Dynamics",
    "text": "Taxonomy of Interactive Dynamics\n\n\nSource: Heer, J. & Shneiderman, B. (2012) “Interactive Dynamics for Visual Analytics” ACM Queue, Vol. 55, No. 4, pp 45-54."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#process-and-provenance",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#process-and-provenance",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Process and Provenance",
    "text": "Process and Provenance\n\n\nRecord analysis histories for revisitation, review and sharing.\nAnnotate patterns to determine findings.\nShare views and annotations to enable collaboration.\nGuide users through analysis tasks or stories.\n\n\n\nVisual analytics is not limited to the generation and manipulation of visualizations—it involves a process of iterative data exploration and interpretation. As a result, visual analytics tools that provide facilities for scaffolding the analysis process will be more widely adopted. Tools should preserve analytic provenance by keeping a record of analyst actions and insights so that the history of work can be reviewed and refined."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Interactive Design Primitive",
    "text": "Interactive Design Primitive\nA framework for effective interactive design in visual analytics application.\n\n\nSource: Roth, R.E. (2012) “Cartographic Interaction Primitive: Framework and Synthesis”. The Cartographic Journal, Vol. 49, No. 4 pp. 376-395."
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive-1",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive-1",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Interactive Design Primitive",
    "text": "Interactive Design Primitive\n\n\nVisual Analytics Objective Primitives\n\n\nInteractive Analytics Operator Primitives"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive-2",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#interactive-design-primitive-2",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Interactive Design Primitive",
    "text": "Interactive Design Primitive"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#animation-in-visual-analytics",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#animation-in-visual-analytics",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "Animation in Visual Analytics",
    "text": "Animation in Visual Analytics\n\n\n\nThe purpose of animation is to facilitate perception of changes when transitioning between related data graphics\nDo not confine to time-series data only\n\n\n\n\nSource: How Many Households"
  },
  {
    "objectID": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#references",
    "href": "lesson/Lesson03/Lesson03-Interactivity in Visual Analytics.html#references",
    "title": "Lesson 3: Interactivity in Visual Analytics",
    "section": "References",
    "text": "References\n\nDynamics for Visual Analysis\nAnimated Transitions in Statistical Data Graphics, IEEE Transactions on Visualization and Computer Graphics, Vol. 13, No. 6, 1240-1247 and the video\nCoordinated Highlighting in Context\nCartographic Interaction Primitive: Framework and Synthesis"
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#what-will-you-learn-from-this-lesson",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#what-will-you-learn-from-this-lesson",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "What will you learn from this lesson?",
    "text": "What will you learn from this lesson?\n\n\nVisual Analytics for Knowledge Discovery\nVisual Analytics Approach for Statistical Testing\nVisual Analytics for Building Better Models\nVisualising Uncertainty\nVariation and Its Discontents\n\n\n\nIn this lesson, I am going to share with you how visual analytics approach can be used to complement conventional statistical testing and model building. Then, We will examine methods for visualising uncertainty. Lastly, I will introduce you to funnel plot, a visual method specially designed to provide a fare comparison among entities in a group."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visually-analytics-for-knowledge-discovery",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visually-analytics-for-knowledge-discovery",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Visually Analytics for Knowledge Discovery",
    "text": "Visually Analytics for Knowledge Discovery\nMotivation: To combine data visualisation and statistical modeling.\n\n\nThis slide highlight the important roles play by visual analytics in the knowledge discovery framework.\nBefore building model, visual analytics can be used to provide better understanding of the variables. These information can be very useful in the subsequent model building process. For example, appropriately designed visual analytics can be used to reveals if there is sign of multicolinearity.\nAfter calibrating the model, visual analytics can be used to reveal the model output for example to check if the model conform to a specific statistical assumption."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visual-statistical-testing",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visual-statistical-testing",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Visual Statistical Testing",
    "text": "Visual Statistical Testing\n\nTo provide alternative statistical inference methods by default.\n\n\n\n\n\n\n\n\n\nIt is important to note that by combining data visualisation and statistical analysis, we need ensure that the methods used are regorous and inline with the statistical principles."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visual-statistical-testing-1",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visual-statistical-testing-1",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Visual Statistical Testing",
    "text": "Visual Statistical Testing\n\nTo follow best practices for statistical reporting.\nFor all statistical tests reported in the plots, the default template abides by the APA gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\nAt the sametime, we also want to ensure that the reports are inline with the academic publication best practices."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visualising-uncertainty",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#visualising-uncertainty",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Visualising Uncertainty",
    "text": "Visualising Uncertainty\nWhy it is important?\n\n\n\nOne of the most challenging aspects of data visualization is the visualization of uncertainty.\n\n\n\n\n\n\nSource: Chart 61, LABOUR FORCE IN SINGAPORE 2019, pg. 52.\n\n\nOne of the most challenging aspects of visual analytics is the visualisation of uncertainty. When we see data point drawn in a specific location, we tend to interpret it as a precise representation of the true value. It is difficult to conceive that a data point could actually lie somewhere it hasn’t been drawn. Yet this scenario is ubiquitous in data visualisation. Nearly every dataset we work with has some uncertainty, and whether and how we choose to represent this uncertainty can make a major difference in how accurately our audience perceives the meaning of the data.\nTwo commonly used approaches to indicate uncertainty are error bars and confidence bands. In this section, we will examine the basic concepts and design pricinples of these methods."
  },
  {
    "objectID": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#variation-and-its-discontents",
    "href": "lesson/Lesson04/Lesson04-Fundamentals of Visual Analytics.html#variation-and-its-discontents",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Variation and Its Discontents",
    "text": "Variation and Its Discontents\nRandom and unfair comparisons\n\n\nReference: Variation and its discontents\n\n\nCentral to quantitative data analysis is an understanding of variation. When we measure multiple occurrences of things to determine how and to what extent they differ, we’re examining variation. Some variation is random and some is caused by factors that we can attempt to identify and perhaps control. Random variation consists of differences in measures that occur routinely, without a specific cause. We should note random variation and move on, because nothing can be done about it. It is noise. It tells us nothing that requires a response.\nInstances of non-random variation are signals; they tell us something useful and provide opportunities for action. Signals that indicate poor performance—an undesirable state—can perhaps be reduced by controlling the causes. Signals that indicate an especially good state of affairs can provide useful insights and opportunities for improvement.\nDespite the significance of variation, relatively few people who work with data in most organizations understand it, especially the nature of randomness. This leads to false conclusions and poor decisions, especially when comparing measures of performance within a set of like entities (e.g., countries or companies). Most organizations spend too much time examining noise: the cacophony of random variation. Learning to distinguish signals from the noise is a fundamental skill of data analysis and performance monitoring. In this article, we’ll take a look at a special version of a scatter plot, called a funnel plot (not to be confused with a funnel chart), which is designed to filter out the noise and shine a spotlight on meaningful variation when we compare performance among entities in a group. Funnel plots address the fact that entities with relatively few occurrences of the thing being measured (a small sample), when compared to entities with many occurrences (a large sample), exhibit a greater degree of random variation, which must be taken into account when comparing them. A little later we’ll take a look at this problem and the solution that funnel plots provide in relation to healthcare data, but first let’s get more familiar with the effects of sample size on randomness.\nConsider the following display (a caterpillar plot) of actual healthcare data. Each data point represents a hospital, with 260 in total. The values are mortality rates following surgeries and the solid horizontal line represents the mean.\nThe sample sizes (number of surgeries reported by each hospital) on which this graph is based range from 7 to 3,151. For this reason it isn’t appropriate to rank the hospitals by mortality rate. The ranking suggests a relationship of relative performance that cannot be determined by the data.\nImagine that, unlike the anonymous version of the graph above, each data point is labeled with the hospital’s name. Can you hear the screams of surgeons from the hospitals with the highest mortality rates in the 4th quartile section of the chart? Can you see the puffed up egos of the surgeons who work at the hospitals with mortality rates of zero in the 1st quartile section? One of the hospitals with a zero mortality rate provided a sample of only seven surgeries.\nNote: You might realize, especially if you work with healthcare data similar to the example above, that a fair comparison of hospitals would require the data to be adjusted not just to account for varying sample sizes but also for varying levels of risk. Some surgeries are more risky than others and some patients, due to varying levels of illness, are more at risk than others. We’ll ignore this for now to keep the example simple."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#content",
    "href": "lesson/Lesson05/Lesson05-VMA.html#content",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Content",
    "text": "Content\nWhat will you learn from this lesson?\n\nUnderstand the characteristics of multidimensional data\nVisual analytics techniques and tools for visualising and analysing multidimensional continuous data\nVisual analytics techniques and tools for visualising and analysing multidimensional categorical data\nSensing both categorical and continuous multidimensional data\nMultidimensional data analysis best practices\n\n\nIn this lesson, I am going to share with you a collection of visual multivariate analysis techniques."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#visual-analytics-techniques",
    "href": "lesson/Lesson05/Lesson05-VMA.html#visual-analytics-techniques",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Visual analytics techniques",
    "text": "Visual analytics techniques\n\nScatterplot Matrix\nTernary plot\nGlyphs\nParallel coordinates\nHeatmap\n\n\nThere are many Visual Multivariate Analysis technqiues. In this lesson, I am going share with you five popular one. They are:"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#introducing-multidimensional-data",
    "href": "lesson/Lesson05/Lesson05-VMA.html#introducing-multidimensional-data",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Introducing Multidimensional Data",
    "text": "Introducing Multidimensional Data\nWine data set\nThere are 13 variables in this data set. 11 of them are in continuous data type, one in ordinal scale and one in nominal scale.\n\n\n\n\n\n \n  \n    fixed acidity \n    volatile acidity \n    citric acid \n    residual sugar \n    chlorides \n    free sulfur dioxide \n    total sulfur dioxide \n    density \n    pH \n    sulphates \n    alcohol \n    quality \n    type \n  \n \n\n  \n    7.4 \n    0.70 \n    0.00 \n    1.9 \n    0.076 \n    11 \n    34 \n    0.9978 \n    3.51 \n    0.56 \n    9.4 \n    5 \n    red \n  \n  \n    7.8 \n    0.88 \n    0.00 \n    2.6 \n    0.098 \n    25 \n    67 \n    0.9968 \n    3.20 \n    0.68 \n    9.8 \n    5 \n    red \n  \n  \n    7.8 \n    0.76 \n    0.04 \n    2.3 \n    0.092 \n    15 \n    54 \n    0.9970 \n    3.26 \n    0.65 \n    9.8 \n    5 \n    red \n  \n  \n    11.2 \n    0.28 \n    0.56 \n    1.9 \n    0.075 \n    17 \n    60 \n    0.9980 \n    3.16 \n    0.58 \n    9.8 \n    6 \n    red \n  \n  \n    7.4 \n    0.70 \n    0.00 \n    1.9 \n    0.076 \n    11 \n    34 \n    0.9978 \n    3.51 \n    0.56 \n    9.4 \n    5 \n    red \n  \n  \n    7.4 \n    0.66 \n    0.00 \n    1.8 \n    0.075 \n    13 \n    40 \n    0.9978 \n    3.51 \n    0.56 \n    9.4 \n    5 \n    red \n  \n\n\n\n\n\n\n\nSource: UCI Machine Learning Repository\n\n\nTable in this slide shows a typical multivariate data sets. This is the popular wine quality data from UCI Machine Learning Repository. It consists of 13 variables in this data set. The first 11 variables are in continuous data type. The quality and type variables are in ordinal scale and nominal scale respectively."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#scatterplot-matrix",
    "href": "lesson/Lesson05/Lesson05-VMA.html#scatterplot-matrix",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Scatterplot Matrix",
    "text": "Scatterplot Matrix\n\n\n\nScatterplot matrix (also known as correlation matrix) is a graphical method used to reveal the relationship between multiple variables pairwisely.\n\n\n\n\n\n\nEach black dot in the scatterplot matrix represents an observation in the data table."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#correlogram",
    "href": "lesson/Lesson05/Lesson05-VMA.html#correlogram",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Correlogram",
    "text": "Correlogram\n\n\n\nCorrelogram uses visual geometrics such as ellipse, circle, square, and bars to replace the scatterplot in correlation matrix.\nIt is very useful to reveal pair-relationships between variables in a large correlation matrix.\nIn this plot, correlation coefficients is colored according to the value.\n\n\n\n\n\n\nFor positive correlation, the colour intensity change from light blue to dark blue when the correlation coefficient values increases from 0 to 1. For negative correlation, the colour intensity change from light red to dark red when the correlation coefficient values increase from 0 to -1. Besides colour, the shape and direction of the ellipse also used to map the correlation coefficient. For example, the direction of the ellipses indicate positive or negative correlation and thin ellipses are shown paired variables with strong linear correlation."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#beyond-visualising-variables-pairwisely",
    "href": "lesson/Lesson05/Lesson05-VMA.html#beyond-visualising-variables-pairwisely",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Beyond Visualising Variables Pairwisely",
    "text": "Beyond Visualising Variables Pairwisely\nThe data"
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#ternary-plot",
    "href": "lesson/Lesson05/Lesson05-VMA.html#ternary-plot",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Ternary Plot",
    "text": "Ternary Plot\n\n\n\nA ternary plot (also known as ternary graph, triangle plot, simplex plot, Gibbs triangle or de Finetti diagram) is a barycentric plot on three variables which sum to a constant, usually in percentage.\nIt graphically depicts the ratios of the three variables as positions in an equilateral triangle."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#visualising-and-analysing-multivariate-data-heatmap-method",
    "href": "lesson/Lesson05/Lesson05-VMA.html#visualising-and-analysing-multivariate-data-heatmap-method",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Visualising and Analysing Multivariate Data: Heatmap method",
    "text": "Visualising and Analysing Multivariate Data: Heatmap method\n\n\n\nA heat map (or heatmap) is a graphical representation of data where the individual values contained in a matrix are represented as colors.\n\n\n\n\n\n\n\nWhen applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in row and colouring the cells within the table.\nHeatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIt is important to note that when the values are all positive or all negative, a colour scheme with different intensity should be used. On the other hand, if the values are in both positive and negative, then, diverging colour scheme should be used."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#visualising-and-analysing-multivariate-data",
    "href": "lesson/Lesson05/Lesson05-VMA.html#visualising-and-analysing-multivariate-data",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Visualising and Analysing Multivariate Data",
    "text": "Visualising and Analysing Multivariate Data\nParallel Coordinates Plot Method\nParallel Coordinates plot or Parallel plot allows to compare the feature of several individual observations on a set of numeric variables.\n\n\nEach vertical bar represents a variable and usually has its own scale. (The units can even be different). Values are then plotted as series of lines connected across each axis. Similar to heatmap, interactivity should be used to complete the data exploration and analysis when using parallel coordinates plot."
  },
  {
    "objectID": "lesson/Lesson05/Lesson05-VMA.html#reference",
    "href": "lesson/Lesson05/Lesson05-VMA.html#reference",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Reference",
    "text": "Reference\n\nRadar Chart.\nTernary plot, this and this.\nFriendly, M (2002) “Corrgrams: Exploratory Displays for Correlation Matrices” The American Statistician, Vol. 56, No. 4, pp. 316-324."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#what-will-you-learn-from-this-lesson",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#what-will-you-learn-from-this-lesson",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "What will you learn from this lesson?",
    "text": "What will you learn from this lesson?\n\n\nCharacteristics of time-series data\nClassic ways of graphing time\nTime-series patterns\nTime-series data visualization\nInteractive techniques for time-series data visualisation\n\n\n\nIn this lesson, I am going to share with you methods and best practice for visualising and analysing time-series data. It is organised into five main sections. First, we will examine different format of time series data. This is followed by a review of selected inspiring data visualisation for revealing time series patterns. In section three, we will examine different time-series patterns graphically. In section 4, I will introduce selected not so commonly used time-series data visualisation techniques. Lastly, in section 5, we will examine how interactivity and animation can be used to enhance visual time-series data discovery."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Characteristics of time-series data",
    "text": "Characteristics of time-series data\nA typical time-series data table\n\n\nThe data table shows a typical time-series data. The first column contains the time series values in calender month and year. It is important to note that the values must not be in character data type. The next four columns are called time-series variables. They can be categorical or numeric data type."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-1",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-1",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Characteristics of time-series data",
    "text": "Characteristics of time-series data\nNot so friendly time-series data\n\n\nThe data table in this slide is an example of time-series data which was not organised in machine understandable time-series manner. As shown on the slide earlier, a machine understandable time-series data must be organised in rows and columns whereby of of the column must contain the date/time values. In this example, the data need to be reformatted before they can be visualised."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-2",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-2",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Characteristics of time-series data",
    "text": "Characteristics of time-series data\nNot so friendly time-series data\n\n\nThis slide shows a typical reporting table with many formatting features such as column sub-total, row sub-total, spacing, rows separators etc. Again, this table need to be tidied before it can be used to build tiem-series visualisation effectively."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-3",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#characteristics-of-time-series-data-3",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Characteristics of time-series data",
    "text": "Characteristics of time-series data\nNot so friendly time-series data\n\n\nThe table on the slide is another good example of not so friendly time-series data set. As you can see, the temporal field was splitted into three columns and the Year and Day fields are in numeric and Month field is in character. Also note that many rows for Year and Month fields were empty. In view of this, this data also need to be tidied before it can be used to build data visualisation."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "A short visual history of time-series graphs",
    "text": "A short visual history of time-series graphs\nPlayfair’s Commercial and Political Atlas (1786)\n\n\nReference: William Playfair’s trade-balance time-series chart, Commercial and Political Atlas, 1786.\n\n\nIn this section, I am going share with you five very well designed time-series data visualisation and hope they inspired you. The first data visualisation is Playfair’s Commercial and Political Atlas (1786). This is not a typical time-series line graph. As you can see, the author put in conscious effort to shade the space between the import and export curve in order to reveal time interval with trade deficit and time interval with trade surplus."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-1",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-1",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "A short visual history of time-series graphs",
    "text": "A short visual history of time-series graphs\nPlayfair’s Chewing at One View Chart (1821)\n\n\nReference: William Playfair’s Price of Wheat\n\n\nThis data visualisation is also a creation of William Playfair. It is make up of two graphical methods namely bar chart and line graph. Bar chart was used to show the price trend of the quarter of wheat and line graph was used to reveal wage trends of labour by the week."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-2",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-2",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "A short visual history of time-series graphs",
    "text": "A short visual history of time-series graphs\nBump Chart shows rank of the most populous cities at each census: 1790-1890\n\n\nAn interactive version here\n\n\nThis data visualisation shows rank of the most populous cities at each census 1790-1890. Instead of using lines, this data visualisation using ellipses. The more recent times were on the left of the data visualisation and the earlier times were on the right. Note that the original data visualisation was static."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-3",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#a-short-visual-history-of-time-series-graphs-3",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "A short visual history of time-series graphs",
    "text": "A short visual history of time-series graphs\nMultiple charts showing records of the Weather in New York City for December, 1912.\n\n\nThis data visualisation shows record of the Weather in New York City for December, 1912. The bold line indicates temperature in degrees Fahrenheit. The light solid line shows wind velocity in miles per hour. The dotted line depicts relative humidity in percentage from readings taken at 8 a.m. and 8 p.m. Arrows portray the prevailing direction of the wind. Initials at the base of the chart show the weather conditions as follows: S, clear; PC, partly cloudy; C, cloudy; R, rain; Sn, snow."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#time-series-graph-that-change-public-understading",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#time-series-graph-that-change-public-understading",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Time-series graph that change public understading",
    "text": "Time-series graph that change public understading\nThe Hockey Stick Chart\n\n\nReference: Michael E. Mann, Raymond S. Bradley, Malcolm K. Hughes (1999) “Northern hemisphere temperatures during the past millennium: Inferences, uncertainties, and limitations”. Geophysical Research Letters, Vol. 26, No. pp. 759-762.\n\n\nHockey stick graphs present the global or hemispherical mean temperature record of the past 500 to 2000 years as shown by quantitative climate reconstructions based on climate proxy records. These reconstructions have consistently shown a slow long term cooling trend changing into relatively rapid warming in the 20th century, with the instrumental temperature record by 2000 exceeding earlier temperatures. It is a good example of how data visualisation can be used to create global awareness of rapid warming in the 20th century."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#time-series-data-patterns",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#time-series-data-patterns",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Time-series data patterns",
    "text": "Time-series data patterns\n\n\nTrend\nVariability\nRate of change\nCo-variation\nCycles\nExceptions\n\n\n\nIn this section, I am going share with you time-series characteristics reveal visually."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\nNot all line graphs should start at zero!\n\n\n\n\n\n\n\n\nIn this section, I am going to share with you some tips when we want to visualise time-series data. This slide shows that by keeping the y-axis starts at zero might not be able to reveal time-series patterns or trends effectivelly. Hence, it is important to customise the y-axis in search a way that it can reveal the time-series patterns effectively like the line graph on the right of the slide."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-1",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-1",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\nMultiple lines in a single graph is less effective than trellis line graph\n\n\n\n\n\n\n\n\nIn order to support effective comparison, sometime trellis line graphs are more functional then a composite line graph as shown on the right of the slide."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-2",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-2",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\nNot all time-series graphs have time on the x-axis\n\n\nSource: Are emerging economies deindustrializing too quickly?.\n\n\nThe connected scatter plot below reveals changes over time by joining each time event points on the scatter plot. The historical trail can be a effective alternative to animation."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-3",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-3",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\nLabel line graph instead of using legend\n\n\n\n\n\n\n\n\nWhen ever possible, it is more effective to label on the line directly as shown on the line graph on the right instead of using legend."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-4",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-4",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\n\nIn order to support comparison over time effectively, reference line should be used.\n\n\n\nLine chart without reference line\n\n\nLine chart with reference line"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-5",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#line-graph-design-tips-5",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Line graph design tips",
    "text": "Line graph design tips\nLine chart with reference band\n\n\nThe reference used don’t have to confine a single line. A confidence interval or quantile range can be used too."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#beyond-line-graph",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#beyond-line-graph",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Beyond Line Graph",
    "text": "Beyond Line Graph\nControl Chart: An analytical line chart\n\n\nControl charts, also known as Shewhart charts (after Walter A. Shewhart) or process-behavior charts. They are a statistical process control tool used to determine if a manufacturing or business process is in a state of control. Beside the average line, there are two additional lines namely the upper control limit (UCL) and lower control limit (LCL). Any data points located beyond UCL or LCL will be flag out as anomalies."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-i-visualising-change-between-two-points-in-time",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-i-visualising-change-between-two-points-in-time",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge I: Visualising Change between Two Points in Time",
    "text": "Challenge I: Visualising Change between Two Points in Time\nBar chart method"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#slopegraphs-come-to-rescue",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#slopegraphs-come-to-rescue",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Slopegraphs come to rescue!",
    "text": "Slopegraphs come to rescue!\n\n\nSlopegraphs compare changes usually over time for a list of nouns located on an ordinal or interval scale.\n\nReference: Slopegraphs for comparing gradients: Slopegraph theory and practice"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge II: Visualising cyclical patterns",
    "text": "Challenge II: Visualising cyclical patterns\nClassic line graph method"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns-1",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns-1",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge II: Visualising cyclical patterns",
    "text": "Challenge II: Visualising cyclical patterns\nSolution: Cycle plot\n\n\nReference: Intro to Cycle Plot"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns-2",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-ii-visualising-cyclical-patterns-2",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge II: Visualising cyclical patterns",
    "text": "Challenge II: Visualising cyclical patterns\nSolution: Sunburst diagram method"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iii-massive-time-series-data",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iii-massive-time-series-data",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge III: Massive Time-series Data",
    "text": "Challenge III: Massive Time-series Data\nClassic line graph method\n\n\nLine graph will not be effective to reveal high number of time series lines (for example 50)"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iii-massive-time-series-data-1",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iii-massive-time-series-data-1",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge III: Massive Time-series Data",
    "text": "Challenge III: Massive Time-series Data\nSolution: Horizon graph\n\n\nBy dividing an area chart into consecutive layers, horizon graphs present time-series data in a compact space while preserving resolution.\n\n\n\nReference: Time on the Horizon"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iv-distribution-over-time",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#challenge-iv-distribution-over-time",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Challenge IV: Distribution over time",
    "text": "Challenge IV: Distribution over time\n\n\nLine graph method\n\n\nBoxplot method"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#alternative-time-series-data-visualisation-methods-calendar-heatmap",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#alternative-time-series-data-visualisation-methods-calendar-heatmap",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Alternative Time-series Data Visualisation methods: Calendar Heatmap",
    "text": "Alternative Time-series Data Visualisation methods: Calendar Heatmap\n\n\nIt is a 2-dimensional calendar view that shows a value over time through color coding it, often with warmer colors indicating higher values (hence heatmap).\n\n\n\nSource: Calender heatmap"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#alternative-time-series-data-visualisation-methods",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#alternative-time-series-data-visualisation-methods",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Alternative Time-series Data Visualisation methods",
    "text": "Alternative Time-series Data Visualisation methods\nStream Graph (also know as ThemeRiver)\n\n\nA streamgraph, or stream graph, is a type of stacked area graph which is displaced around a central axis, resulting in a flowing, organic shape.\n\n\n\nReference: Steam graph"
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#visualising-change-over-time",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#visualising-change-over-time",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "Visualising Change Over Time",
    "text": "Visualising Change Over Time\nAnimated bubble plot (or motion chart)\n\n\nA motion chart displays changes over time by showing movement within the two-dimensional space and changes in the size and color of the bubbles."
  },
  {
    "objectID": "lesson/Lesson06/Lesson06-VisTime.html#references",
    "href": "lesson/Lesson06/Lesson06-VisTime.html#references",
    "title": "Lesson 6: Visualising and Analysing Time-Oriented Data",
    "section": "References",
    "text": "References\nClaus. O. Wilke (2019) Fundamentals of Data Visualisation, O’Reilly. USA. Chapter 13 Visualizing time series and other functions of an independent variable and Chapter 14 Visualizing trends\nIntroduction to Cycle Plots\nSlopegraphs for comparing gradients: Slopegraph theory and practice\nThe Development of the Horizon Graph"
  },
  {
    "objectID": "lesson.html",
    "href": "lesson.html",
    "title": "Lesson Plan",
    "section": "",
    "text": "Lesson\nDate\nVenue\nTopic\nRemarks\n\n\n\n\n1\n14/1\nSCIS1 SR B1-1\nIntroduction to Visual Analytics\n\n\n\n2\n21/1\nSCIS1 SR B1-1\nDesigning Graphs to Enlighten\n\n\n\n3\n28/1\nYPHSL SR B2-01\nInteractivity in Visual Analytics\n\n\n\n4\n4/2\nYPHSL SR B2-01\nFundamentals of Visual Analytics\n\n\n\n5\n11/2\nSCIS1 SR B1-1\nVisual Multivariate Analysis\n\n\n\n6\n18/2\nSCIS1 SR B1-1\nIt’s About Time\n\n\n\n7\n25/2\nSCIS1 SR B1-1\nVisualising and Analysing Geographic Data\n\n\n\n\n4/3\nSCIS1 SR B1-1\nRecess\n\n\n\n8\n11/3\nSCIS1 SR B1-1\nNetwork Data Visualisation and Analysis\n\n\n\n9\n18/3\nSCIS1 SR B1-1\nInformation Dashboard Design\n\n\n\n10\n25/3\nSCIS1 SR B1-1\nVisualising Financial Data"
  },
  {
    "objectID": "outline/Lesson01_outline.html",
    "href": "outline/Lesson01_outline.html",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "",
    "text": "Course Overview\nMotivation of Visual Analytics\nWhat Visual Analytics is\nVisual Analytics in History\nIntents of Visual Analytics Applications\nVisual Analytics Techniques: basic graphical methods\nVisual Analytics Tools"
  },
  {
    "objectID": "outline/Lesson01_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson01_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats.\nHands-on Exercise 1 in html format."
  },
  {
    "objectID": "outline/Lesson01_outline.html#in-class-exercise",
    "href": "outline/Lesson01_outline.html#in-class-exercise",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "In-class Exercise",
    "text": "In-class Exercise\nBy the end of this lesson, you will gain hands-on experience on:\n\ncreating the course website by using Quarto and RStudio,\nmanaging the website by using git/github by using RStudio\npublishing the website onto Netlify server"
  },
  {
    "objectID": "outline/Lesson01_outline.html#self-reading-before-lesson",
    "href": "outline/Lesson01_outline.html#self-reading-before-lesson",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "Self-reading Before Lesson",
    "text": "Self-reading Before Lesson\n\nWebinars\n\nThe best Hans Rosling talks you’ve ever seen.\nVIVA – What is Visual Analytics?\nWhy Visual Analytics\nVisual Analytics - Mastering the Information Age"
  },
  {
    "objectID": "outline/Lesson01_outline.html#readings",
    "href": "outline/Lesson01_outline.html#readings",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "Readings",
    "text": "Readings\n\nThomas, J.J. & Cook, K.A. (2006) “A Visual Analytics Agenda”, ‘’IEEE Computer Graphics and Applications’’, January 2006, Vol.26(1), pp.10-13\nChabot, C (2009) “Demystifying Visual Analytics”, ‘’IEEE Computer Graphics and Applications’’, March 2009, Vol.29(2), pp.84-87.\nThe 5 Most Influential Data Visualizations of All Time\nJ.J. Thomas and K.A. Cook, eds. (2005) Illuminating the Path: The Research and Development Agenda for Visual Analytics, IEEE CS Press.\nJun, Yuan et. al. (2020) “A survey of visual analytics techniques for machine learning”, Computational Visual Media. doi.org/10.1007/s41095-020-0191-7.\nCui, Wenqiang (2019) “Visual Analytics: A Comprehensive Overview”, IEEE Access."
  },
  {
    "objectID": "outline/Lesson01_outline.html#statistical-graphics-methods",
    "href": "outline/Lesson01_outline.html#statistical-graphics-methods",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "Statistical Graphics Methods",
    "text": "Statistical Graphics Methods\n\nAge-sex Pyramid\n\nPopulation pyramid\nAge-Sex and Population Pyramids: The Most Useful Graphs in Population Geography\nPopulation Pyramid Singapore\n\n\n\nPareto Chart\n\nPareto chart\nRevising the Pareto Chart\n\n\n\nTrellis Display\n\nThe Visual Design and Control of Trellis Display\nTrellis display\nTrellis Displays vs. Interactive Graphics"
  },
  {
    "objectID": "outline/Lesson01_outline.html#all-about-tableau",
    "href": "outline/Lesson01_outline.html#all-about-tableau",
    "title": "Lesson 1: Introduction to Visual Analytics",
    "section": "All About Tableau",
    "text": "All About Tableau\n\nThings about Tableau you must know!\n\nPolaris: A System for Query, Analysis,and Visualization of Multidimensional Relational Databases\nTableau Technology\nShow Me: Automatic Presentation for Visual Analysis\nWhitepaper: Visual Analysis for Everyone\nAnalytics Best Practices in Tableau\n\n\n\nLearning Tableau\n\nGetting Started\nTableau Interface\nGetting Started with Visual Analytics\nFormatting\nThe Formatting Pane\nReference lines\nGetting Started with Data also self-learn the remaining videos under ’‘’Connecting to Data’’’\nGetting Started with Tableau Prep Builder. This is a brand-new product from Tableau designed to help everyone quickly and confidently combine, shape, and clean their data for analysis. You can learn more about Tableau Data Prep here. You are encouraged to view all the 12 videos under ’‘’Tableau Prep’’’."
  },
  {
    "objectID": "outline/Lesson02_outline.html",
    "href": "outline/Lesson02_outline.html",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "",
    "text": "Human perception and information processing\nPerceptual and design principles for effective visual analytics\nPrinciples of Graphic Design\n\nRules for Encoding Values in Graph\nJunkCharts\nPractical Guides for Using Colour in Charts\nData-ink"
  },
  {
    "objectID": "outline/Lesson02_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson02_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson 2: Designing Graphs to Enlighten in html and pdf formats\nHandout of Hands-on Exercise 2 in html and pdf formats."
  },
  {
    "objectID": "outline/Lesson02_outline.html#readings",
    "href": "outline/Lesson02_outline.html#readings",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Readings",
    "text": "Readings\n\nCore Readings\n\nClaus O. Wilke Fundamentals of Data Visualisation, Chapter 1-5, 17-26.\nData Visualization: Clarity or Aesthetics?\nClarity or Aesthetics? Part 2 – A Tale of Four Quadrants\nClarity or Aesthetics? Part 3 – Tips for Achieving Both\n\n\n\nOptional Readings\n\nJunk Charts Trifecta Checkup: The Definitive Guide\n7 Basic Rules for Making Charts and Graphs\nQuantitative Literacy Across the Curriculum\nTapping the Power of Visual Perception\nSometimes We Must Raise Our Voices\nBest Practices for Understanding Quantitative Data\nData Visualization: Rules for Encoding Values in Graph\nChoosing Colors for Data Visualization\nLine Graphs and Irregular Intervals: An Incompatible Partnership\nDos and don’ts of data visualisation- Usability guidelines for improving your visualisations"
  },
  {
    "objectID": "outline/Lesson02_outline.html#learning-from-examples",
    "href": "outline/Lesson02_outline.html#learning-from-examples",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Learning from Examples",
    "text": "Learning from Examples\n\nMistakes, we’ve drawn a few\nFT stories through charts and graphics\nThree Steps to Make Your Data Clearer\nWhen your own data contradicts your headline"
  },
  {
    "objectID": "outline/Lesson02_outline.html#all-about-tableau",
    "href": "outline/Lesson02_outline.html#all-about-tableau",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "All About Tableau",
    "text": "All About Tableau\n\nWhite Paper\n\nWhich chart or graphis right for you?\nGood Enough to Great: A Quick Guide for Better Data Visualizations\n\n\n\nTutorial\n\nGetting Started with Dashboards and Stories\nGetting Started with Calculation\nCalculation Syntax\nIntroduction to LOD Expressions\nIntro to Table Calculations\nModifying Table Calculations\nAggregate Calculations\nDate Calculations\nLogic Calculation\nString Calculation\nNumber Calculation\nType Calculation\nConceptual Topics with LOD Expressions\nAggregation and Replication with LOD Expressions\nNested LOD Expressions"
  },
  {
    "objectID": "outline/Lesson02_outline.html#visual-analytics-methods-of-the-week",
    "href": "outline/Lesson02_outline.html#visual-analytics-methods-of-the-week",
    "title": "Lesson 2: Designing Graphs to Enlighten",
    "section": "Visual Analytics Method(s) of the Week",
    "text": "Visual Analytics Method(s) of the Week\n\nBoxplot\n\nUnderstanding Boxplots\nRegina L. Nuzzo (2016) “The Box Plots Alternative for Visualizing Quantitative Data”, PR&M, Volume8, Issue3, pp. 268-272.\n\n\n\nViolin Plots\n\nViolin Plot-wikipedia\nHintze, Jerry L.; Nelson, Ray D. (1998). “Violin Plots: A Box Plot-Density Trace Synergism”. The American Statistician. 52 (2): 181–4\nViolin Plot by LondonSODA.\n\n\n\nNotched Box Plots\n\nNotched Box Plots\n\n\n\nDot Plots\n\nDot plots\nDot Plots: A Useful Alternative to Bar Charts\nThe dot plot: A graphical tool for data analysis and presentation\nLeland Wilkinson (1999) “Dot Plot”, Statistical Computing and Graphics, Vol. 53, No. 3, pp. 276-281.\n\n\n\nPie chart and Bar chart\n\nUnderstanding Pie Charts\nTracey L. Weissgerber et. al. (2015) “Beyond Bar and Line Graphs: Time for a New Data Presentation Paradigm”, PLoS Biology.\n\n\n\nRaincloud Plots\n\nAllen M, Poggiali D, Whitaker K et al. “Raincloud plots: a multi-platform tool for robust data. visualization” [version 2; peer review: 2 approved]. Welcome Open Res 2021, pp. 4:63.\n\n\n\nDiverging Stacked Bar Chart\n\nDesign of Diverging Stacked Bar Charts for Likert Scales and Other Applications\nWhen Are 100% Stacked Bar Graphs Useful?\nThe case against diverging stacked bars\nAre diverging 100% stacked bars useless?\nRethinking the divergent stacked bar chart — placing the stronger views in the center\n\n\n\nPacked Bars\n\nIntroducing packed bars, a new chart form\nrPackedBar: Packed Bar Charts with ‘plotly’"
  },
  {
    "objectID": "outline/Lesson03_outline.html",
    "href": "outline/Lesson03_outline.html",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "",
    "text": "Different types of interaction techniquee\nThe role of Interaction in visual analytics\nThe concept of linked multiple views\nInteractive analytics best practices"
  },
  {
    "objectID": "outline/Lesson03_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson03_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 3 in html format."
  },
  {
    "objectID": "outline/Lesson03_outline.html#readings",
    "href": "outline/Lesson03_outline.html#readings",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "Readings",
    "text": "Readings\n\nCore readings\n\nDynamics for Visual Analysis\nAnimated Transitions in Statistical Data Graphics, IEEE Transactions on Visualization and Computer Graphics, Vol. 13, No. 6, 1240-1247 and the video\nCoordinated Highlighting in Context\nCartographic Interaction Primitive: Framework and Synthesis"
  },
  {
    "objectID": "outline/Lesson03_outline.html#optional-readings",
    "href": "outline/Lesson03_outline.html#optional-readings",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "Optional readings",
    "text": "Optional readings\n\nEnhancing Visual Analysis by Linking Multiple Views of Data\nThe Eyes Have It: A Task by Data Type Taxonomy for Information Visualizations\nThe Sunrest Path to Visual Discovery\nToward a Deeper Understanding of the Role of Interaction in Information Visualization\nSnap-together visualization: can users construct and operate coordinated visualizations?\nGeneralized Selection via Interactive Query Relaxation\nBrushing"
  },
  {
    "objectID": "outline/Lesson03_outline.html#all-about-tableau",
    "href": "outline/Lesson03_outline.html#all-about-tableau",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "All About Tableau",
    "text": "All About Tableau\n\nSorting\nDrill Down and Hierarchies\nWays to Filter\nUsing the Filter Shelf\nInteractive Filters\nWhere Tableau Filters\nAdditional Filtering Topics\nParameters\nParameter Actions\nBasic Tooltips\nViz in Tooltip\nDashboard Interactivity Using Actions\nCreate data that moves you with viz animations\nThe benefits of animating your data visualisations\nTableau in Motion: Tableau’s New Native Viz Animations\nHow to use Animations in Tableau 2020.1"
  },
  {
    "objectID": "outline/Lesson03_outline.html#visual-analytics-methods-of-the-week",
    "href": "outline/Lesson03_outline.html#visual-analytics-methods-of-the-week",
    "title": "Lesson 3: Interactivity in Visual Analytics: Principles and Methods",
    "section": "Visual Analytics Method(s) of the Week",
    "text": "Visual Analytics Method(s) of the Week\n\nScatterplot with marginal Distribution\n\nScatter Plots with Marginal Densities – An Example for Doing Exploratory Data Analysis with Tableau and R\nGot a Scatter Plot? Learn How to Add Marginal Histograms\nHow to Make Marginal Histograms and Bar Charts in Tableau\nMarginal Histograms — They’re Not Just for Scatterplots"
  },
  {
    "objectID": "outline/Lesson04_outline.html",
    "href": "outline/Lesson04_outline.html",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "",
    "text": "Visual Analytics for Knowledge Discovery\nVisual Analytics Approach for Statistical Testing\nVisual Analytics for Building Better Models\nVisualising Uncertainty\n\nWhy Visualising Uncertainty?\nBasic Statistical Concepts Related to Uncertainty\nUnivariate Graphical Methods for Visualising Uncertainty\n\nError bars\nConfidence strips\nRidge plot\n\nBivariate Graphical Methods for Visualising Uncertainty\n\nFunnel plot\n\n\nVariation and Its Discontents"
  },
  {
    "objectID": "outline/Lesson04_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson04_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 4\n\nHands-on Exercise 4: Visual Statistical Analysis\nHands-on Exercise 4: Visualising Uncertainty\nHands-on Exercise 4: Building Funnel Plot with R"
  },
  {
    "objectID": "outline/Lesson04_outline.html#readings-on-visualising-uncertainty",
    "href": "outline/Lesson04_outline.html#readings-on-visualising-uncertainty",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "Readings on Visualising Uncertainty",
    "text": "Readings on Visualising Uncertainty\n\nWhy It’s So Hard for Us to Visualize Uncertainty\nVisualizing the Uncertainty in Data\nUncertainty + Visualization, Explained\n\n\nError Plots\n\nError bar\n\n\n\nFunnel Plots\n\nVariation and Its Discontents: Funnel Plots for Fair Comparisons\nWhat are the chances of successful fertility treatment?\nThree-fold variation in UK bowel cancer death rates(?)\nUsing funnel plots in public health surveillance\nGraph Makeover: Where same-sex couples live in the US\nUsing maps and funnel plots to explore variation in place of death from cancer within London, 2002–2007"
  },
  {
    "objectID": "outline/Lesson04_outline.html#all-about-tableau",
    "href": "outline/Lesson04_outline.html#all-about-tableau",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "All About Tableau",
    "text": "All About Tableau\n\nVisualising Uncertainty\n\nShowing uncertainty in survey results\nNot a funnel cake, nor funnel charts, it’s funnel plots!\nFunnel Plot in Tableau\nCreating Error Bars or CI Bars\nStandard errors and confidence intervals in Tableau"
  },
  {
    "objectID": "outline/Lesson04_outline.html#all-about-r",
    "href": "outline/Lesson04_outline.html#all-about-r",
    "title": "Lesson 4: Fundamentals of Visual Analytics",
    "section": "All about R",
    "text": "All about R\n\nggstatsplot: An extension of ggplot2 package for creating statistical graphics with details from statistical tests.\nggdist: An R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nperformance: An R package provides utilities for computing indices of model quality and goodness of fit including provides many functions to check model assumptions visually.\ninfer: An R package specially designed to perform statistical inference using an expressive statistical grammar that coheres with the tidyverse design framework. The library also includes functions for visualising the distribution of the simulation-based inferential statistics or the theoretical distribution (or both)."
  },
  {
    "objectID": "outline/Lesson05_outline.html",
    "href": "outline/Lesson05_outline.html",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "",
    "text": "Correlation Matrix\n\nCorrelogram\n\nMultivariate Data Visualisation\n\nternary plot\nGlyphs or Star Plot\nheatmap\nparallel coordinate plot\nparallel plot\n\nSpace-constrained visualization of hierarchies\n\nTreemaps\nSunburst diagram"
  },
  {
    "objectID": "outline/Lesson05_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson05_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 5\n\nBuilding Ternary Plot with R.\nVisualising Correlation Matrices with R.\nBuilding Heatmap for Visualising and Analysing Multivariate Data.\nBuilding Parallel Coordinates Plot with R."
  },
  {
    "objectID": "outline/Lesson05_outline.html#readings",
    "href": "outline/Lesson05_outline.html#readings",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "Readings",
    "text": "Readings\n\nCore Readings\nMultivariate Methods\n\nAn Introduction to Visual Multivariate Analysis\nCorrgrams: Exploratory Displays for Correlation Matrices\nTernary Plot\nMultivariate Data Glyphs\nParallel Coordinates\nWikipedia: Heatmap\n\nTreemaps\n\nShneiderman, Ben (2008) Treemaps for space-constrained visualization of hierarchies\nExtending the Utility of Treemaps with Flexible Hierarchy\n\n\n\nOptional Readings\nMultivariate Methods\n\nThe scatter-plot matrix: a great tool\nA Graphical Display of Large Correlation Matrices\nTernary Diagram\nReading a Ternary Diagram\nMultidimensional Detective\nParallel Coordinates\nMultivariate Analysis Using Parallel Coordinates\nGhosts on the Radar — Why Radar Charts Are Easily Misread\nKeep Radar Graphs Below the Radar - Far Below\nA Critique of Radar Charts\nRadar: More Evil Than Pie\n\nTreemaps\n\nTreemaps\nDiscovering Business Intelligence Using Treemap Visualization\n10 Lessons in Treemap Design\nBederson, Benjamin B.; Shneiderman, Ben; Wattenberg, Martin (2002). Ordered and quantum treemaps: Making effective use of 2D space to display hierarchies. ACM Transactions on Graphics. 21 (4): 833.\nBruls, Mark; Huizing, Kees; van Wijk, Jarke J. (2000). Squarified treemaps. In de Leeuw, W.; van Liere, R. Data Visualization 2000: Proc. Joint Eurographics and IEEE TCVG Symp. on Visualization]\nUS Economic Census Treemap\nTreeCovery: Coordinated dual treemap visualization for exploring the Recovery Act\nJuice’s Stimulus Bill Explorer\nFundexplorer\nMap of the Market\nThe HIVE Group\nTruck Sales Slip, Tripping Up Chrysler\nNewsmap\nObama’s 2011 Budget Proposal: How It’s Spent"
  },
  {
    "objectID": "outline/Lesson05_outline.html#r-packages",
    "href": "outline/Lesson05_outline.html#r-packages",
    "title": "Lesson 5: Visual Multivariate Analysis",
    "section": "R Packages",
    "text": "R Packages\n\nCorrelation Matrix\n\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals.\n\n\n\nHeatmap\nStatic heatmap\n\nheatmap() of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nInteractive Heatmap\n\nheatmaply: Make Interactive Cluster Heat Maps Using ‘plotly’\nd3heatmap: Make Interactive Heat Maps Using ‘htmlwidgets’ and ’D3.js.\niheatmapr makes complex, interactive heatmaps. Detail information are available at here.\n\n\n\nTreemaps\n\nTreemap package.\n\nCreating a Treemap in R\ntreemap: mapping to color palettes\nSimple Steps to Create Treemap in R\n\ntreemapify: Draw Treemaps in ‘ggplot2’\n\nIntroduction to treemapify\nInteractive visualization with R-Shiny versus with Tableau: Treemaps\n\n\n\n\nSunburst Diagram\n\nsunburstR\nSunburst 2.0.0\nCreate Basic Sunburst Graphs with ggplot2"
  },
  {
    "objectID": "outline/Lesson06_outline.html",
    "href": "outline/Lesson06_outline.html",
    "title": "It’s About Time",
    "section": "",
    "text": "Characteristics of time-series data\nA short visual history of time-series graphs\nTime-series patterns\nTime-series data visualization Methods\n\nLine graph\nControl chart\nSlopegraph\nCycle plot\nHorizon graph\nSunburst diagram\nCalendar Heatmap\nStream Graph\n\nInteractive techniques for time-series data visualisation\nAnimation techniques for time-series visualisation"
  },
  {
    "objectID": "outline/Lesson06_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson06_outline.html#lesson-slides-and-hands-on-notes",
    "title": "It’s About Time",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 6 in html format."
  },
  {
    "objectID": "outline/Lesson06_outline.html#readings",
    "href": "outline/Lesson06_outline.html#readings",
    "title": "It’s About Time",
    "section": "Readings",
    "text": "Readings\n\nCore Readings\n\nA taxonomy of temporal data visualization techniques\nEdward Tufte’s “Slopegraphs”\nIntroduction to Cycle Plots\nVisualizing Change: An Innovation in Time-Series Analysis\nThe Development of the Horizon Graph\n\n\n\nAdditional Readings\n\nwhat is a slopegraph?\nSlopegraph Update\nTime on the Horizon\nTimeSearcher\nWhat is a slopegraph?\nDonahue, Rafe M.J. Fundamental Statistical Concepts in Presenting Data: Principles for Constructing Better Graphics. This article provide a real world example of building truthful and functional time series graph.\nHockey stick graph at wiki.\nMichael E. Mann, Raymond S. Bradley, Malcolm K. Hughes (1999) “Northern hemisphere temperatures during the past millennium: Inferences, uncertainties, and limitations”. Geophysical Research Letters, Vol. 26, No. pp. 759-762.\nThe Guardian (2010) “Hockey stick graph took pride of place in IPCC report, despite doubts”."
  },
  {
    "objectID": "outline/Lesson06_outline.html#all-about-tableau",
    "href": "outline/Lesson06_outline.html#all-about-tableau",
    "title": "It’s About Time",
    "section": "All About Tableau",
    "text": "All About Tableau\n\nSlopegraphs in Tableau\nHorizon Graph\nViz Variety Show: When to use heatmap calendars"
  },
  {
    "objectID": "outline/Lesson07_outline.html",
    "href": "outline/Lesson07_outline.html",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "Introducing map\nProperties of geographical data\nTypology of map\nThematic mapping techniques\n\nProportional symbol map\nChoropleth map\nData Classification\n\nAlternative mapping techniques"
  },
  {
    "objectID": "outline/Lesson07_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson07_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHands-on Exercises:\nHands-on Exercise 7: Choropleth Mapping in R html\nHands-on Exercise 7: Proportional Symbol Mapping in R html\nHandout of Hands-on Exercise 7: Analytical Mapping in html."
  },
  {
    "objectID": "outline/Lesson07_outline.html#readings",
    "href": "outline/Lesson07_outline.html#readings",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Readings",
    "text": "Readings\n\nCore Reading\n\nThe Concept of Map Symbols\nProportional Symbols\nChoropleth map\nChoropleth Maps\nThe Basics of Data Classification\n\n\n\nAdditional Readings\n\nChoropleth Maps – A Guide to Data Classification\nBivariate Choropleth\nValue-by-alpha maps\nWhat to consider when creating choropleth maps\nChoropleth Mapping with Exploratory Data Analysis\nCartogram Maps: Data Visualization with Exaggeration\nCartogram\nWhen Maps Shouldn’t Be Maps\nWhat to consider when creating choropleth maps"
  },
  {
    "objectID": "outline/Lesson07_outline.html#visualising-geographic-data-tableau-methods",
    "href": "outline/Lesson07_outline.html#visualising-geographic-data-tableau-methods",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Visualising Geographic Data: Tableau Methods",
    "text": "Visualising Geographic Data: Tableau Methods\n\nBasic Tutorial\n\nMaps and Geographic Data Analysis in Tableau. This chapter from the User Guide of Tableau provide a comprehensive overview of the mapping concepts and Tableau methods. I strongly recommend you to read the chapter at least once.\nLive Training: Mapping\nGetting Started with Mapping\nMaps in Tableau\nEditing Unrecognized Location\nSpatial Files\nThe Density Mark Type (Heat maps)\nExpanding Tableau’s Mapping Capabilities\nCustom Geocoding\nPolygon Maps\nBackground Images\n\n\n\nBeyond the Basic\n\nAdvanced Mapping with Tableau\n10 ways to add value to your dashboards with maps\n3 Ways to Make Magnificent Maps in Tableau\nHow to Make Trellis / Tile / Small Multiple Maps in Tableau"
  },
  {
    "objectID": "outline/Lesson07_outline.html#geovisual-analytics-r-methods",
    "href": "outline/Lesson07_outline.html#geovisual-analytics-r-methods",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "GeoVisual Analytics: R methods",
    "text": "GeoVisual Analytics: R methods\n\nsf package\n\nSimple Features for R\nReading, Writing and Converting Simple Features\nManipulating Simple Feature Geometries\nManipulating Simple Features\nPlotting Simple Features\nMiscellaneous\nSpherical geometry in sf using s2geometry\n\n\n\nraster package\n\nraster reference\nraster package\n\n\n\nstars\n\nstars reference\nSpatiotemporal Arrays: Raster and Vector Datacubes\nIntroduction\nstars tidyverse methods\nStatistical modelling with stars objects\n\n\n\ntmap package\n\ntmap reference\ntmap: get started!\ntmap: what is changed in recent versions?\nTennekes, M., (2018)tmap: Thematic Maps in R, Journal of Statistical Software, 84(6), 1-39.\n\n\n\nmicromap package\n\nmicromap provides functions simplifies the creation of linked micromap plots.\nLinked Micromaps\n\n\n\ngeofacet package\n\ngeofacet provides geofaceting functionality for ggplot2. Geofaceting arranges a sequence of plots of data for different geographical entities into a grid that strives to preserve some of the original geographical orientation of the entities.\nIntroduction to geofacet"
  },
  {
    "objectID": "outline/Lesson08_outline.html",
    "href": "outline/Lesson08_outline.html",
    "title": "Lesswon 8: Network Data Visualisation and Analysis",
    "section": "",
    "text": "Introduction to Graph Data Visualisation\n\nBasic principles of network graph\nGraph data visualisation in actions\n\nNetwork Graph Data\n\nNetwork data sets\nGraph data format\nGraph Database\n\nNetwork Graph Visualisation Tools\nDesigner toolkit\n\nGephi\n\nProgrammer toolkit\n\nR packages\n\nGraph layouts\n\nNode-and-link layouts\nForce-directed layout\nNode-only layout\nAdjacency matrix\n\nVisual Attributes\n\nKey node attributes\nKey edge attributes\nBundles, shapes, images, and more\n\nVisual Analysis of Network Graphs\n\nRelationships\nHierarchies\nCommunities\n\nFlows\nSpatial networks"
  },
  {
    "objectID": "outline/Lesson08_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson08_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesswon 8: Network Data Visualisation and Analysis",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 8 in html and pdf formats."
  },
  {
    "objectID": "outline/Lesson08_outline.html#readings",
    "href": "outline/Lesson08_outline.html#readings",
    "title": "Lesswon 8: Network Data Visualisation and Analysis",
    "section": "Readings",
    "text": "Readings\n\nVisual Analysis of Complex Networks for Business Intelligence with Gephi\nGraph Drawing\nGraph Analytics - Lesson Learned and Challenges Ahead\nLearning to Read and Interpret Network Graph Data Visualizations\nThe Visualization of Networks\nViZster: Visualizing Online Social Networks\nAdam Perer. “Finding Beautiful Insights in the Chaos of Social Network Visualizations”. In ’‘’Beautiful Visualization’’’. O’Reilly Press.\nVisual Complexity"
  },
  {
    "objectID": "outline/Lesson08_outline.html#all-about-r",
    "href": "outline/Lesson08_outline.html#all-about-r",
    "title": "Lesswon 8: Network Data Visualisation and Analysis",
    "section": "All About R",
    "text": "All About R\n\nWrangling Network Data\n\ntidygraph\ntidygraph 1.1 – A tidy hope\ntidygraph\n\n\n\nVisualisation and Analysis\nggraph\n\nggraph\nAnnouncing ggraph\n1 giraffe, 2 giraffe, GO!\nLayouts\nNodes\nEdges\ntidygraph and ggraph\n\nvizNetwork\n\nvisNetwork: Network Visualization using ‘vis.js’ Library\nIntroduction to visNetwork\nvisNetwork, an R package for interactive network visualization\n\nCircular Plot\n\ncirclize: circular visualization in R\nCircular Visualization in R"
  },
  {
    "objectID": "outline/Lesson09_outline.html",
    "href": "outline/Lesson09_outline.html",
    "title": "Lesson 9: Information Dashboard Design",
    "section": "",
    "text": "Introducing information dashboard\nInformation dashboard design best practices\nCommon mistakes in dashboard design\nIdeal graphs for information dashboard\n\nBullet graph\nSparklines\nBandlines"
  },
  {
    "objectID": "outline/Lesson09_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson09_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 9: Information Dashboard Design",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 9 in html and pdf formats."
  },
  {
    "objectID": "outline/Lesson09_outline.html#reference",
    "href": "outline/Lesson09_outline.html#reference",
    "title": "Lesson 9: Information Dashboard Design",
    "section": "Reference",
    "text": "Reference\n\nCore Readings\n\nBullet Graph Design Specification\n\n\n\nAdditional Readings\n\nDashboard Confusion\nDashboard Confusion Revisited\nDashboard Design for Rich and Rapid Monitoring\nPervasive Hurdles to Effective Dashboard Design\nAssessing the Effectiveness of a New Dashboard’s Design\nGuide to Creating Dashboards People Love\nDashboard Design: Taking a Metaphor Too Far\nWhy Most Dashboards Fail\nPatent Failure: The USPTO’s Oversized but Undernourished New Dashboard\nOracle-Have you no shame?\nThe Vicious Cycle of Data Impoverishment"
  },
  {
    "objectID": "outline/Lesson10_outline.html",
    "href": "outline/Lesson10_outline.html",
    "title": "Lesson 10: Financial Data Visualisation and Analysis",
    "section": "",
    "text": "Introduction Financial Data\n\nTime-series financial data\n\nFinancial Data Visualisation and Analysis Methods\n\nTreemap\nHorizon Graph\nCandlestick"
  },
  {
    "objectID": "outline/Lesson10_outline.html#lesson-slides-and-hands-on-notes",
    "href": "outline/Lesson10_outline.html#lesson-slides-and-hands-on-notes",
    "title": "Lesson 10: Financial Data Visualisation and Analysis",
    "section": "Lesson Slides and Hands-on Notes",
    "text": "Lesson Slides and Hands-on Notes\n\nLesson slides in html and pdf formats\nHandout of Hands-on Exercise 10 in html and pdf formats."
  },
  {
    "objectID": "Quarto.html",
    "href": "Quarto.html",
    "title": "All About Quarto",
    "section": "",
    "text": "Getting Started\nRStudio IDE\nUsing R\nHTML Basics"
  },
  {
    "objectID": "Quarto.html#create-websites-and-blogs",
    "href": "Quarto.html#create-websites-and-blogs",
    "title": "All About Quarto",
    "section": "Create websites and blogs",
    "text": "Create websites and blogs\n\nCreating a Website\nWebsite Navigation\nDocument Listings"
  },
  {
    "objectID": "Quarto.html#authoring-guide",
    "href": "Quarto.html#authoring-guide",
    "title": "All About Quarto",
    "section": "Authoring Guide",
    "text": "Authoring Guide\n\nMarkdown Basics\nFigures\nTables\nDiagrams\nCitations & Footnotes\nCross References\nArticle Layout\n\nUseful web resources\n\nAwesome Quarto. This github repository provides a comprehensive listing of Quarto resources. It should be the second stop (after Quarto homepage) if you need to look for revelent materials about Quarto."
  },
  {
    "objectID": "R.html",
    "href": "R.html",
    "title": "R Resources",
    "section": "",
    "text": "R for Data Science by Garrett Grolemund and Hadley Wickham.\nModern R with the tidyverse by Bruno Rodrigues. Chapter 2 provides a detail discussion on R data objects.\nBrendan R. E. Ansell Introduction to R - tidyverse\nThe Comprehensive Guide to Installing R Packages from CRAN, Bioconductor, GitHub and Co.. This article provides useful tips on how to install R packages from different sources.\nR Workflow"
  },
  {
    "objectID": "R.html#blog-post",
    "href": "R.html#blog-post",
    "title": "R Resources",
    "section": "Blog post",
    "text": "Blog post\n\nR Workflow from Statistical Thinking."
  },
  {
    "objectID": "R4Vis.html",
    "href": "R4Vis.html",
    "title": "R for Visual Analytics",
    "section": "",
    "text": "ggplot2\nggplot2 – The R graph Gallery\nIntroduction to R Graphics with ggplot2\nggplot2 - A Short Tutorial\nggplot2 介紹\n\n\n\n\n\nHadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2020)ggplot2: Elegant Graphics for Data Analysis (3rd Edition, online version).\nKieran Healy (2019) Data Visualization: A practical introduction. This is the online version.\nAravind Hebbali (2020) Data Visualization with ggplot2\nWinston Chang (2020) R Graphics Cookbook (2nd edition, online version)\nRob Kabacoff (2020) Data Visualization with R\nZuguang Gu Circular Visualization in R. Last visit: 27/12/2020.\nZach Bogart & Joyce Robbins (2020) Exploratory Data Analysis & Visualization\nBBC Visual and Data Journalism cookbook for R graphics\nNordmann, E., McAleer, P., Toivo, W., Paterson, H. & DeBruine, L. Data visualisation using R, for researchers who don’t use R\n\n\n\n\n\nHow to make any plot in ggplot2?\nThe Complete ggplot2 Tutorial - Part1 | Introduction To ggplot2 (Full R code)\nThe Complete ggplot2 Tutorial - Part 2 | How To Customize ggplot2 (Full R code)\nTop 50 ggplot2 Visualizations - The Master List (With Full R Code)\nggplot2 Quickref\nData visualization with ggplot2\nggplot Wizardary\n\n\n\n\n\nggplot2 workshop part 1\nggplot2 workshop part 2\nMake Beautiful Graphs in R: 5 Quick Ways to Improve ggplot2 Graphs\nOutlier 2021—ggplot wizardy: my favorite tricks and secrets for beautiful plots in R by Cédric Scherer\n\n\n\n\n\nggVis\nggmap\nggtern, an extension to ggplot2 specifically for the plotting of ternary diagrams.\nggExtra, a collection of functions and layers to enhance ggplot2. The main function is ggMarginal, which can be used to add marginal histograms/boxplots/density plots to ggplot2 scatterplots.\nggthemes, some extra themes, geoms, and scales for ‘ggplot2’. Provides ‘ggplot2’ themes and scales that replicate the look of plots by Edward Tufte, Stephen Few, ‘Fivethirtyeight’, ‘The Economist’, ‘Stata’, ‘Excel’, and ‘The Wall Street Journal’, among others. Provides ‘geoms’ for Tufte’s box plot and range frame.\nGGally extends ‘ggplot2’ by adding several functions to reduce the complexity of combining geometric objects with transformed data. Some of these functions include a pairwise plot matrix, a two group pairwise plot matrix, a parallel coordinates plot, a survival plot, and several functions to plot networks.\nsjPlot:Data Visualization for Statistics in Social Science\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the plots themselves and targeted primarily at behavioral sciences community to provide a one-line code to produce information-rich plots.\nggside allows the user to add graphical information about one of the main panel’s axis. This is particularly useful for metadata for discrete axis, or summary graphics on a continuous axis such as a boxplot or a density distribution. These vignette and article provide useful introduction.\nPatchwork is a package designed to make plot composition in R extremely simple and powerful. It is mainly intended for users of ggplot2 and goes to great lengths to make sure ggplots are properly aligned no matter the complexity of your composition. The Getting Started page explains the main features of the package.\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualizing distributions and uncertainty. It is designed for both frequentist and [https://mjskay.github.io/ggdist/articles/freq-uncertainty-vis.html] visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization: for frequentist models, one visualizes confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”)); for Bayesian models, one visualizes probability distributions (see the tidybayes package, which builds on top of ggdist)."
  },
  {
    "objectID": "R4Vis.html#interactive-data-visualisation-with-r",
    "href": "R4Vis.html#interactive-data-visualisation-with-r",
    "title": "R for Visual Analytics",
    "section": "Interactive Data Visualisation with R",
    "text": "Interactive Data Visualisation with R\n\nplotly R\n\nplotly: Create Interactive Web Graphics via ‘plotly.js’\nInteractive web-based data visualization with R, plotly, and shiny\nPlotly R Open Source Graphing Library\nGetting Started with Plotly and ggplot2\n\n\n\nggigraph\n\nggigraph lets R users to make ggplot interactive."
  },
  {
    "objectID": "R4Vis.html#other-r-graphics-packages",
    "href": "R4Vis.html#other-r-graphics-packages",
    "title": "R for Visual Analytics",
    "section": "Other R graphics packages",
    "text": "Other R graphics packages\n\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals. [https://cran.r-project.org/web/packages/corrgram/index.html]\nvcd, Visualization techniques, data sets, summary and inference procedures aimed particularly at categorical data. Special emphasis is given to highly extensible grid graphics.\ntmap offers a flexible, layer-based, and easy to use approach to create thematic maps, such as choropleths and bubble maps."
  },
  {
    "objectID": "Rt.html",
    "href": "Rt.html",
    "title": "R Tips & Tricks",
    "section": "",
    "text": "Importing multiple files into R"
  },
  {
    "objectID": "ShinyResources.html",
    "href": "ShinyResources.html",
    "title": "Shiny Resources",
    "section": "",
    "text": "Shiny from R Studio\nLearn Shiny\nFunction reference\nThe Shiny Cheat sheet\n\n\n\n\n\nThe Past and Future of Shiny. A must view presentation.\nA new way to build your Shiny app’s UI.\nShiny Programming Practices.\nShiny UI Editor Feature Tour.\nShiny UI Editor Project Walkthrough.\nGetting Started with {shinytest2} Part I.\nGetting Started with {shinytest2} Part 2.\nGetting Started with {shinytest2} Part 3.\n\n\n\n\n\nHadley Wickham (2020) Mastering Shiny. Everything you need to know about Shiny can be found here. It is not an easy to read book but worth investing time and effort to read.\nColin Fay, Sébastien Rochette, Vincent Guyader, Cervan Girard (2020) Engineering Production-Grade Shiny Apps\nDavid Granjon (2020) Outstanding User Interfaces with Shiny\nHow to Build a Shiny Application from Scratch\nShiny 入門\n\n\n\n\n\nGallery\nShiny Contest Winners 2019 - Full List\nShiny Contest Winners 2020\nShiny Contest Winners 2021\nFifteen New Zealand government Shiny web apps\nIntroducing the New Zealand Trade Intelligence Dashboard\nShiny for Good: R Shiny Projects with a Positive Impact"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#content",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#content",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Content",
    "text": "Content\n\nWhat is a Web-enabled Visual Analytics Application?\nWhy building Web-enabled Visual Analytical Application?\nEvolution of web-based Technology\nGetting to Know Shiny"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#what-is-a-web-enabled-visual-analytics-application",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#what-is-a-web-enabled-visual-analytics-application",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "What is a Web-enabled Visual Analytics Application?",
    "text": "What is a Web-enabled Visual Analytics Application?\n\n\n\nFocuses and emphasises on interactivity and effective integration of techniques from data analytics, visualization and human-computer interaction (HCI)."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nShiny: Overview\n\n\n\nShiny is an open source package from Posit (formally called RStudio).\nIt provides a web application framework to create interactive web applications (visualization) called “Shiny apps”.\nTo learn more about Shiny, visit its homepage"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-1",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-1",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nWhat is so special about Shiny?\n\n\nIt allows R users:\n\nto build and share highly interactive web-enabled applications without having to invest significant among of time and efforts to master core web design technologies such as html5, Javascript and CSS.\nto integrate the analytical and visualisation packages of R without having to change from one programming language to another."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-2",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-2",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nUnderstanding the architecture\n\nEvery Shiny app is maintained by a computer running R."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-3",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-3",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nThe Structure of a Shiny app\n\n\n\nA Shiny app comprises of two components, namely:\n\na user-interface script, and\na server script."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-4",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-4",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nShiny’s user-interface, ui.R\n\nThe ui.R script controls the layout and appearance of a shiny app.\n\nIt is defined in a source script name ui.R.\nActually, ui is a web document that the user gets to see, it is based on the famous Twitter bootstrap framework, which makes the look and layout highly customizable and fully responsive.\nIn fact, you only need to know R and how to use the shiny package to build a pretty web application. Also, a little knowledge of HTML, CSS, and JavaScript may help."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-5",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-5",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nShiny’s server server.R\n\nThe server.R script contains the instructions that your computer needs to build your Shiny app.\nYou are expected to:\n\nknow how to programme with R.\nfamiliar with Tidyverse, specifically dplyr, tidyr and ggplot2"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-6",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-6",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nShiny Examples\nThe Shiny package has eleven built-in examples that each demonstrates how Shiny works."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-7",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#getting-to-know-shiny-7",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Getting to Know Shiny",
    "text": "Getting to Know Shiny\nRunning Shiny example\n\n\n\nlibrary(shiny)\nrunExample(\"01_hello\")"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#building-a-shiny-app",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#building-a-shiny-app",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Building a Shiny app",
    "text": "Building a Shiny app\n\nA Shiny app can be in a form of a single file called app.R.\nAlternatively, a Shiny app can be also created using separate ui.R and server.R files.\nThe seperate files way is preferred when the app is complex and involves more codes."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-layout",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-layout",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Layout",
    "text": "Shiny Layout\n\nShiny ui.R scripts use the function fluidPage to create a display that automatically adjusts to the dimensions of your user’s browser window.\nYou lay out your app by placing elements in the fluidPage function.\ntitlePanel and sidebarLayout are the two most popular elements to add to fluidPage. They create a basic Shiny app with a sidebar."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-layout-panels",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-layout-panels",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Layout Panels",
    "text": "Shiny Layout Panels\n\nPanels are used to group multiple elements into a single element that has its own properties.\nEspecially important and useful for complex apps with a large number of inputs and outputs such that it might not be clear to the user where to get started."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-inputs",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-inputs",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Inputs",
    "text": "Shiny Inputs\nAn overview of Shiny Inputs\n\n\n\nInputs are what gives users a way to interact with a Shiny app.\nShiny provides many input functions to support many kinds of interactions that the user could have with an app.\n\n\n\n\n\nReference: Refer to 2 Basic UI of Master Shiny to learn more about Shiny UI usage and arguments."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-inputs-1",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-inputs-1",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Inputs",
    "text": "Shiny Inputs\nInputs syntax\n\n\n\nAll input functions have the same first two arguments: inputId and label.\nThe inputId will be the name that Shiny will use to refer to this input when you want to retrieve its current value.\nIt is important to note that every input must have a unique inputId.\nThe label argument specifies the text in the display label that goes along with the input widget.\nEvery input can also have multiple other arguments specific to that input type."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-output",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-output",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Output()",
    "text": "Shiny Output()\nAn overview of Shiny Output()\n\nAfter creating all the inputs, we should add elements to the UI to display the outputs.\nTo display output, add it to fluidPage() with an Output() function.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSimilarly to the input functions, all the output functions have a outputId argument that is used to identify each output, and this argument must be unique for each output.\nEach output needs to be constructed in the server code later."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-output-1",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-output-1",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny Output()",
    "text": "Shiny Output()\nShiny Output() options\n\n\n\nOutputs can be any object that R creates and that we want to display in our app - such as a plot, a table, or text."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny server.R",
    "text": "Shiny server.R\nBuilding an output\nThere are three rules to build an output in Shiny, they are:\n\nSave the output object into the output list (remember the app template - every server function has an output argument).\nBuild the object with a render() function, where is the type of output.\nAccess input values using the input list (every server function has an input argument)\n\n\n\n\n\n\n\nNote\n\n\nThe third rule is only required if you want your output to depend on some input."
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r-1",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r-1",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny server.R",
    "text": "Shiny server.R\nA generic Shiny render() syntax"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r-2",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#shiny-server.r-2",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Shiny server.R",
    "text": "Shiny server.R\nShiny render()"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#the-shinyapp",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#the-shinyapp",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "The shinyApp()",
    "text": "The shinyApp()\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIt is important to add shinyApp() at the end of your Shiny application.\n\n\n\n\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#programming-shiny-survival-tip",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#programming-shiny-survival-tip",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Programming Shiny: Survival Tip!",
    "text": "Programming Shiny: Survival Tip!\n\n\n\n\n\n\nTip\n\n\n\nAlways run the entire script, not just up to the point where you’re developing code.\nSometimes the best way to see what’s wrong is to run the app and review the error.\nWatch out for commas!"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#building-shiny-application-survival-tip",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#building-shiny-application-survival-tip",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "Building Shiny Application: Survival Tip!",
    "text": "Building Shiny Application: Survival Tip!\n\n\nWhat can we learn from Lego?\n\n\n\nSketch the storyboard\nBuilding the app incrementally\n\nUsing prototyping approach\nStart as simple as possible\nAdding features one at a time\n\nSave -> Run App"
  },
  {
    "objectID": "ShinyWorkshop/Shiny1/Shiny1.html#references",
    "href": "ShinyWorkshop/Shiny1/Shiny1.html#references",
    "title": "Building Web-enabled Visual Analytics Applications with Shiny: Shiny basic",
    "section": "References",
    "text": "References\n\nHadley Wickham (2021) Mastering Shiny, O’Reilly Media. This is a highly recommended book.\nBuilding Web Applications with Shiny, especially Module 1 and 2.\nShiny Three Parts Tutorial.\nOnline Function reference\nThe basic parts of a Shiny app\nHow to build a Shiny app\nThe Shiny Cheat sheet\n\nBeyond Uncle Google! Last but not least, when you need help\n\nHow to get help"
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#overview",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#overview",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Overview",
    "text": "Overview\nIn this lesson, selected advanced methods of Shiny will be discussed. You will also gain hands-on experiences on using these advanced methods to build Shiny applications.\nBy the end of this lesson, you will be able to:\n\ngain further understanding of the reactive feature of Shiny and Shiny’s functions that support reactive flow,\nbuild interactive Shiny application by using plotly R and\nbuild static, interactive and reactive geovisualisation application by using tmap"
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#reactive-flow",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#reactive-flow",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Reactive Flow",
    "text": "Reactive Flow\nBy default, Shiny application is Reactive!"
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-building-a-reactive-scatter-plot-using-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-building-a-reactive-scatter-plot-using-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Building a reactive scatter plot using Shiny",
    "text": "In-class Exercise: Building a reactive scatter plot using Shiny\n\n\nIn this in-class exercise, you are going to explore advanced reactive features.\nTo get started, you need to do the followings:\n\nstart a new Shiny Application\nload the necessary R package, namely Shiny and tidyverse\nimport the data file (i.e. Exam_data.csv )\nbuild a basic scatterplot look similar to the figure on the right."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#embedding-interactive-graphs-in-r-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#embedding-interactive-graphs-in-r-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Embedding Interactive Graphs in R Shiny",
    "text": "Embedding Interactive Graphs in R Shiny\nThe plotly way\n\n\nTwo approaches: - Using plotly directly, or - Plot the basic visualisation using ggplot2, then wrap the visualisation object into plotly object using ggplotly().\nReference: - Plotly R Open Source Graphing Library - 17 Server-side linking with shiny of Interactive web-based data visualization with R, plotly, and shiny"
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-embedding-a-drill-down-bar-chart-in-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-embedding-a-drill-down-bar-chart-in-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Embedding a drill-down bar chart in Shiny",
    "text": "In-class Exercise: Embedding a drill-down bar chart in Shiny\nIn this exercise, you will learn how to embed a drill-down bar chart in Shiny by using event_data() of plotly."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-embedding-a-static-map-in-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-embedding-a-static-map-in-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Embedding A Static Map in Shiny",
    "text": "In-class Exercise: Embedding A Static Map in Shiny\nIn this exercise, you will learn how to embed a static map in Shiny by using renderPlot(). By the end of this exercise, you will be able to plot a static map on Shiny display as shown below."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-building-a-choropleth-mapping-application",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-building-a-choropleth-mapping-application",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Building a choropleth mapping application",
    "text": "In-class Exercise: Building a choropleth mapping application\nIn this exercise, you will learn how to build a choropleth mapping application by using tmap and Shiny."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#embedding-an-interactive-map-in-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#embedding-an-interactive-map-in-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Embedding an interactive map in Shiny",
    "text": "Embedding an interactive map in Shiny\nIn this exercise, you will learn how to embed an interactive map in Shiny by using renderTmap() and tmapOutput() of tmap package. The interactive map is a proportional symbol map showing distribution of winnings by branches/outlets."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-reactive-map-in-r-shiny",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#in-class-exercise-reactive-map-in-r-shiny",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Reactive Map in R Shiny",
    "text": "In-class Exercise: Reactive Map in R Shiny\nIn this exercise, you will learn how to create reactive map in Shiny. The output will look similar to the figure below."
  },
  {
    "objectID": "ShinyWorkshop/Shiny2/Shiny2.html#references",
    "href": "ShinyWorkshop/Shiny2/Shiny2.html#references",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "References",
    "text": "References\n\nHadley Wickham (2020) Mastering Shiny: Build Interactive Apps, Reports, and Dashboards Powered by R online version\n\nChapter 3 Basic reactivity\nChapter 13 Why reactivity?\nChapter 14 The reactive graph\nChapter 15 Reactive building blocks\nChapter 16 Escaping the graph\n\nCarson Sievert (2019) Interactive web-based data visualization with R, plotly, and shiny, online version.\n\nChapter 17 Server-side linking with shiny"
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#overview",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#overview",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Overview",
    "text": "Overview\nIn this lesson, selected advanced methods of Shiny will be discussed. You will also gain hands-on experiences on using these advanced methods to build Shiny applications.\nBy the end of this lesson, you will be able to:\n\nunderstanding the basic development cycle of creating apps, making changes, and experimenting with the results,\ndebug errors in the codes,\nbuild complex Shiny application using module, and\nimprove the productivity of Shiny applications development"
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#working-with-shiny-layout",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#working-with-shiny-layout",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Working with Shiny Layout",
    "text": "Working with Shiny Layout\nShiny includes a number of facilities for laying out the components of an application. This guide describes the following application layout features:\n\nA sidebarLayout(): for placing a sidebarPanel() of inputs alongside a mainPanel() output content.\nCustom layouts using Shiny’s grid layout system (i.e., fluidRow() & column()).\nSegmenting layouts using the tabsetPanel() and navlistPanel() functions.\nCreating applications with multiple top-level components using the navbarPage() function."
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#multi-page-layouts",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#multi-page-layouts",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Multi-page layouts",
    "text": "Multi-page layouts\n\n\nShiny provides several functions for building multi-page layout, they are:\n\ntabsetPanel() + tabPanel()\nnavlistPanel() + tabPanel()\nnavbarMenu() + tabPanel()"
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#shiny-themes",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#shiny-themes",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Shiny Themes",
    "text": "Shiny Themes\n\n\n\n\nShiny v1.6 and higher integrates with the bslib package providing easy access to modern versions of Bootstrap, Bootswatch themes, as well as custom themes that can even be modified in real time!\nTo use bslib in your own Shiny app, pass a bs_theme() object to the theme argument of the relevant page layout function, such as navbarPage() or fluidPage().\nInside bs_theme(), you can specify a version of Bootstrap and (optionally) a Bootswatch theme (e.g. cyborg)\n\n\n\n\nlibrary(shiny)\nlibrary(tidyverse)\nlibrary(bslib)     \nexam <- read_csv(\"data/Exam_data.csv\")\nui <- fluidPage(\n  theme = bs_theme(bootswatch = \"cyborg\"), \n  titlePanel(\"Pupils Examination Results Dashboard\"),"
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#introducing-shiny-module",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#introducing-shiny-module",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Introducing Shiny Module",
    "text": "Introducing Shiny Module\n\nAs Shiny applications grow larger and more complicated, modules are used to manage the growing complexity of Shiny application code.\nFunctions are the fundamental unit of abstraction in R, and we designed Shiny to work with them.\nWe can write UI-generating functions and call them from our app, and we can write functions to be used in the server function that define outputs and create reactive expressions."
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#debugging",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#debugging",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Debugging",
    "text": "Debugging\n\n\n\nProgramming == Frustration?\n\nSource: The original article.\n\nThree main cases of problems which we’ll discuss below:\n\nYou get an unexpected error. This is the easiest case, because you’ll get a traceback which allows you to figure out exactly where the error occurred.\nYou don’t get any errors, but some value is incorrect. Here, you’ll need to use the interactive debugger, along with your investigative skills to track down the root cause.\nAll the values are correct, but they’re not updated when you expect. This is the most challenging problem because it’s unique to Shiny, so you can’t take advantage of your existing R debugging skills."
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#standard-r-debugging-tools",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#standard-r-debugging-tools",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Standard R debugging tools",
    "text": "Standard R debugging tools\n\nTracing\n\ntracebacks\nprint()/cat()/str()\nrenderPrint eats messages, must use cat(file = stderr(), ““…)\nAlso consider shinyjs package’s logjs, which puts messages in the browser’s JavaScript console\n\n\nDebugger\n\nSet breakpoints in RStudio\nbrowser()\nConditionals: if (!is.null(input$x)) browser()"
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#in-class-exercise-working-with-rstudios-interactive-debugger",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#in-class-exercise-working-with-rstudios-interactive-debugger",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "In-class Exercise: Working with RStudio’s Interactive Debugger",
    "text": "In-class Exercise: Working with RStudio’s Interactive Debugger\n\n\nIn this hands-on Exercise, you will learn how to work with the interactive debugger in RStudio.\n\nDouble click prototype7a.\nDouble click on prototype7a.rproj file to open the project file in RStudio.\nClick on app.R file to open the Shiny app file on RStudio\nAdd a call to browser() in your source code (for example line 5).\nClick in Run App button to run the Shiny app.\n\n\n\n\nNext (press n): executes the next step in the function. Note that if you have a variable named n, you’ll need to use print(n) to display its value.\nContinue (press c): leaves interactive debugging and continues regular execution of the function. This is useful if you’ve fixed the bad state and want to check that the function proceeds correctly.\nStop (press Q): stops debugging, terminates the function, and returns to the global workspace. Use this once you’ve figured out where the problem is, and you’re ready to fix it and reload the code."
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#shinytest",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#shinytest",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "Shinytest",
    "text": "Shinytest\n\nShinytest uses snapshot-based testing strategy.\nThe first time it runs a set of tests for an application, it performs some scripted interactions with the app and takes one or more snapshots of the application’s state.\nThese snapshots are saved to disk so that future runs of the tests can compare their results to them."
  },
  {
    "objectID": "ShinyWorkshop/Shiny3/Shiny3.html#references",
    "href": "ShinyWorkshop/Shiny3/Shiny3.html#references",
    "title": "Building Web-enabled Visual Analytics Application with Shiny: Beyond the basic",
    "section": "References",
    "text": "References\nShiny Layout\n\nApplication layout guide\n\nShiny Module\n\nChapter 19 Shiny modules of Mastering Shiny.\nModularizing Shiny app code, online article\nCommunication between modules. This is a relatively old article, some functions have changed.\nShiny Modules\nShiny Modules (part 1) : Why using modules?\nShiny Modules (part 2): Share reactive among multiple modules\nShiny Modules (part 3): Dynamic module call"
  },
  {
    "objectID": "Syllabus.html",
    "href": "Syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "In this competitive global environment, the ability to explore visual representation of business data interactively and to detect meaningful patterns, trends and exceptions from these data are increasingly becoming an important skill for data analysts and business practitioners. Drawing from research and practice on Data Visualisation, Human-Computer Interaction, Data Analytics, Data Mining and Usability Engineering, this course aims to share with you how visual analytics techniques can be used to interact with data from various sources and formats, explore relationship, ’‘’detect the expected and discover the unexpected’’’ without having to deal with complex statistical formulas and programming.\nThe goals of this course are:\n\nTo share with you the principles, best practices and methods of visual analytics\nTo provide you hands-on experiences in using commercial-off-the-shelf visual analytics software and programming tools to design visual analytics applications"
  },
  {
    "objectID": "Syllabus.html#learning-objectives",
    "href": "Syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon successful completion of the course, students will be able to:\n\nUnderstand the basic concepts, theories and methodologies of visual analytics.\nAnalyse data using appropriate visual thinking and visual analytics techniques.\nPresent data using appropriate visual communication and graphical methods.\nDesign and implement cutting-edge visual analytics system for supporting decision making.\n\n\nCompetencies\n\nExplaining the concepts and principles of Visual Analytics.\nDescribing the differences between Visual Analytics, Data Visualisation, Statistical Graphs and Infographics.\nExplaining the basic concept of visual variables and applying these concepts and best practices in designing data-driven static graphs.\nExplaining interactive techniques and best practices, and applying these techniques in designing interactive data visualisation.\nUnderstanding the data characteristics of numerical data and building data visualisation by using appropriate visually driven univariate and bivariate data analytics methods.\nUnderstanding the characteristics of multivariate data and building data visualisation by using appropriate multivariate visualisation methods.\nUnderstanding the characteristics of time-series data and building data visualisation by using appropriate time-series visualisation methods.\nUnderstanding the characteristics of geographical data and building data visualisation by using appropriate geovisualisation methods.\nUnderstanding the characteristics of network data and building data visualisation by using appropriate network graph visualisation methods.\nExplain the concepts and principles of Information Dashboard.\nBuilding analytical dashboard by using Commercial off-the-shelf (COTS) software.\nDesigning visual analytics application programmatically by using free and open source software and packages."
  },
  {
    "objectID": "Syllabus.html#basic-modules",
    "href": "Syllabus.html#basic-modules",
    "title": "Syllabus",
    "section": "Basic Modules",
    "text": "Basic Modules\nThis course comprises ten integrated components as shown below:"
  },
  {
    "objectID": "Syllabus.html#prerequisites",
    "href": "Syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nThere are no prerequisites for the class. However, students taking this course must be willing to learn R programming framework. For students who are new to R, you are encouraged to consult the following resources prior to the lesson starts:\n\nGarrett Grolemund & Hadley Wickham (2020) R for Data Science. This book is highly recommended to anybody who are interested to understand how to do ’‘’Modern Data Science’’’ by using ’‘’tidyverse’’’ principles and methods.\n\n王敏杰 数据科学中的 R 语言.\n\nYou don’t have to finish reading either one of them before lesson starts. Take your time, review them from time to time. You will find yourself learning something new each time you revisit the book."
  },
  {
    "objectID": "Syllabus.html#course-assessment",
    "href": "Syllabus.html#course-assessment",
    "title": "Syllabus",
    "section": "Course Assessment",
    "text": "Course Assessment\nThe assessment for this course consists of four major components, namely:\n\nIn-class Hands-on exercise and class participation,\nDataViz Makeover\nTake-home exercises,\nVisual Analytics Project.\n\nThere will be no mid-term test or final examination for this course.\n\nIn-class Exercise and Class Participation\nA strict requirement for each class meeting is to complete the assigned readings and to try out the hands-on exercises before coming to class. Readings will be provided from the textbook on technical information and from provided documents and articles on business applications of Visual Analytics. Students are required to review the recommended readings and class exercises before coming to class. Without preparation, the learning and discussions would not be as meaningful. Student sharing of insights from readings and hands-on exercises of assigned materials in class participation will form a large part of the learning in this course.\nDuring lesson, students are required to complete a series of hands-on exercises using either Tableau or R. In general, these exercises are guided if Tableau is used. For R programming session, hands-on guides will be shared on RPubs before lesson starts. By the end of each lesson, students are required to upload their in-class exercise onto eLearn for reviewing. The exercises will be briefly reviewed after collection. Students will be given 10 points for correctly completing the exercise, 7-9 points for partially completed and correct work, and 0 points if absent. Up to 100 points can be accumulated during the term.\n\n\nTake-home Exercise\nThe take-home exercise provides students with the opportunity to revise and practice the R packages and programming skills they had learned in class at home. It is a weekly exercise. Each exercise is designed to be completed within 1.5-2 hours. The exercise is not a repetition of the in-class exercise but it requires students to be innovative and creative in applying appropriate R packages to design enlightening and yet functional data visualisation for analytics purposes.\nStudents may work together to help one another with R programming issues and discuss the materials that constitute the take-home exercise. However, each student is required to prepare and submit the take-home exercise (including any computer work) on their own. Cheating is strictly prohibited. Cheating includes but not limited to: plagiarism and submission of work that is not the student’s\n\n\nVisual Analytics Project\nThe purpose of the project is to provide students with first hand experiences on collecting, processing and analysing large business data using real world data. A project may involve developing new methods or implementing visual analytics system to support analytic tasks in specific domains. Alternatively, a project may be in the form of application development by integrating analytical tools within a visual analytics environment. Students are encouraged to focus on research topics that are relevant to their field of study. It should address a concrete visual analytics problem and should propose a novel and creative solution.\nFor more details please refer to Visual Analytics Project page."
  },
  {
    "objectID": "Syllabus.html#grading-summary",
    "href": "Syllabus.html#grading-summary",
    "title": "Syllabus",
    "section": "Grading Summary",
    "text": "Grading Summary\nThe grading distribution of this course is as follows:\n\nIn-class Exercise and Class Participation 20%\nTake-home Exercise 50%\nVisual Analytics Project 30%\n\nProject blog 15%\nPoster 10%\nPractice research paper 25%\nArtifact 50%\n\n\nThere will be no mid-term test and final examination for this course."
  },
  {
    "objectID": "Syllabus.html#words-of-encouragement",
    "href": "Syllabus.html#words-of-encouragement",
    "title": "Syllabus",
    "section": "Words of Encouragement",
    "text": "Words of Encouragement\nFor the next 10 weeks, your learning journey will be very bumpy, especially come to R programming\n\nLearning R can be difficult at first—it’s like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like ggplot2 — made this wise observation:\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\nEven experienced programmers find themselves bashing their heads against seemingly intractable errors.\n\nIf you’re finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, and don’t hesitate to approach me.\nThe students who have a bad time in this course are the ones who don’t work with one another to learn. We are a learning community, and we should help each other to learn.\nIf you understand something and someone is struggling with it, try and help them. If you are struggling, take a breath, and try to pinpoint what you are struggling with.\nOur goal is to be better programmers each day, not to be the perfect programmer. There’s no such thing as a perfect programmer. I’ve been learning new things almost every day.\nI promise you can succeed in this class as long as you are willing to learn, practice, be open minded and don’t give up easily."
  },
  {
    "objectID": "Syllabus.html#core-readings",
    "href": "Syllabus.html#core-readings",
    "title": "Syllabus",
    "section": "Core Readings",
    "text": "Core Readings\nClaus. O. Wilke (2019) Fundamentals of Data Visualisation, O’Reilly. USA\nCairo, Alberto (2013) The Functional Art: An Introduction to Information Graphics and Visualization, New Riders, Berkeley, CA. This book is available at SMU eLibrary.\nFew, Stephen (2004) Show Me the Numbers: Designing Tables and Graphs to Enlighten, Analytics Press, Oakland, USA.\nFew, Stephen (2009) Now You See It: Simple Visualization Techniques for Quantitative Analysis, Analytics Press, Oakland, USA."
  },
  {
    "objectID": "Syllabus.html#other-important-information",
    "href": "Syllabus.html#other-important-information",
    "title": "Syllabus",
    "section": "Other Important Information",
    "text": "Other Important Information\n\nAcademic Integrity\nAll acts of academic dishonesty (including, but not limited to, plagiarism, cheating, fabrication, facilitation of acts of academic dishonesty by others, unauthorized possession of exam questions, or tampering with the academic work of other students) are serious offences. All work (whether oral or written) submitted for purposes of assessment must be the student’s own work. Penalties for violation of the policy range from zero marks for the component assessment to expulsion, depending on the nature of the offense. When in doubt, students should consult the instructors of the course. Details on the SMU Code of Academic Integrity may be accessed at http://www.smuscd.org/resources.html\n\n\nAccessibility and Accommodations\nSMU strives to make learning experiences accessible for all. If you anticipate or experience physical or academic barriers due to disability, please let the instructor know immediately. You are also welcome to contact the university’s disability support team if you have questions or concerns about academic accommodations: included@smu.edu.sg Please be aware that the accessible tables in our seminar room should remain available for students who require them.\n\n\nEmergency Preparedness for Teaching and Learning (EPTL)\nAs part of emergency preparedness, Instructors may conduct lessons online via the WebEx platform during the term, to prepare students for online learning. During an actual emergency, students will be notified to access the WebEx platform for their online lessons. The class schedule will mirror the current face-to-face class timetable unless otherwise stated."
  },
  {
    "objectID": "Tableau.html",
    "href": "Tableau.html",
    "title": "Tableau Resources",
    "section": "",
    "text": "Tableau home page\nTraining and Tutorials\nTableau Desktop User Guide\nTableau Prep Builder User Guide\nVisual Gallery\nTableau Public"
  },
  {
    "objectID": "Tableau.html#white-papers",
    "href": "Tableau.html#white-papers",
    "title": "Tableau Resources",
    "section": "White papers",
    "text": "White papers\n\n10 Best Practices for Building Effective Dashboards\nTips for creating effective, engaging data visualizations"
  },
  {
    "objectID": "Tableau.html#blogs-that-inspired",
    "href": "Tableau.html#blogs-that-inspired",
    "title": "Tableau Resources",
    "section": "Blogs that inspired",
    "text": "Blogs that inspired\n\nThe Information Lab\nDataRemixed\nPlayfairData\nData Revelations, especially Visualizing Survey Data and Steven’s Blog"
  },
  {
    "objectID": "Tableau.html#from-data-to-tada",
    "href": "Tableau.html#from-data-to-tada",
    "title": "Tableau Resources",
    "section": "From data to tada",
    "text": "From data to tada\n\nUsing data visualization to make better decisions—faster\n17 key traits of data literacy\nInspiring change with data visualization\n5 important elements of dashboard design"
  },
  {
    "objectID": "Tableau.html#tableau-tips-and-tricks",
    "href": "Tableau.html#tableau-tips-and-tricks",
    "title": "Tableau Resources",
    "section": "Tableau Tips and Tricks",
    "text": "Tableau Tips and Tricks\n\nRelationships, Joins and Unions in Tableau 2020.2, this Youtube video explains selected data management features introduced in Tableau 2020.2. (updated on 8th Feb 2021)."
  },
  {
    "objectID": "take-home.html",
    "href": "take-home.html",
    "title": "Take-home Exercise",
    "section": "",
    "text": "The take-home exercise provides students the opportunity to revise and practice the R packages and programming skills they learnt in-class at home. It is a weekly exercise. Students are expected to spend not more than an hour a day to work of the exercise instead of complete the exercise at one go.\nThe exercise is not a repetition of the in-class exercise but it requires students to be innovative and creative by applying appropriate R packages to design enlightening and yet functional data visualisation for analytics purposes. Students are encouraged to create multiple data visualisation and compare their pros and cons before finalising the best design."
  },
  {
    "objectID": "take-home.html#take-home-exercises",
    "href": "take-home.html#take-home-exercises",
    "title": "Take-home Exercise",
    "section": "Take-home Exercises",
    "text": "Take-home Exercises\n\nTake-home Exercise 1\nTake-home Exercise 2\nTake-home Exercise 3\nTake-home Exercise 4\nTake-home Exercise 5\nTake-home Exercise 6"
  },
  {
    "objectID": "take-home.html#submission-instructions",
    "href": "take-home.html#submission-instructions",
    "title": "Take-home Exercise",
    "section": "Submission Instructions",
    "text": "Submission Instructions\nThis is an individual assignment. You are required to work on the take-home exercises and prepare submission individually.\n\nThe take-home exercise submission must be written by using distill for R Markdown. It can be in either distill article or distill blog format. You are required to publish the assignment report on Netlify and provide the link on the take-home exercise submission page on elearn.\nYou are also required to push the take-home exercise folder and data onto your individual Github repository and provide the link on the take-home exercise submission page on eLearn."
  },
  {
    "objectID": "take-home.html#submission-date",
    "href": "take-home.html#submission-date",
    "title": "Take-home Exercise",
    "section": "Submission date",
    "text": "Submission date\nYour completed take-home exercise is due at 11:59pm on every Friday."
  },
  {
    "objectID": "take-home.html#learning-from-seniors",
    "href": "take-home.html#learning-from-seniors",
    "title": "Take-home Exercise",
    "section": "Learning from seniors",
    "text": "Learning from seniors\n\nAY2021-22 April Term\n\nTake-home Exercise 1\n\nAng Bi Lian\nTAN HUI QI RANICE"
  },
  {
    "objectID": "take-home_ex/TH_EX01.html",
    "href": "take-home_ex/TH_EX01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "Creating data visualisation beyond default\n\nThe Task\nAge-sex pyramid is an analytical visualisation commonly used by demographers to reveal the structure of population by gender and age group. In this take-home exercise, you are required to reveal the demographic structure of Singapore at planning area level by using age-sex pyramid method. Instead of plotting a single age-sex pyramid, however, you are required to display nine selected planning areas on a single view by using trellis display (also know as small-multiple plot).\n\n\nThe Designing Tool\nFor the purpose of this take-home exercise, Tableau desktop should be used to design the analytical visualisation.\n\n\nThe Data\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022 should be used to prepare the analytical visualisation. It is available at Department of Statistics, Singapore(in short SingStat).\n\n\nThe Write-up\nThe write-up of the take-home exercise should include but not limited to the followings:\n\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the senior submission I shared for example 1 and 2.\nA write-up of not more than 500 words to discuss the patterns reveal by the analytical visualisation prepared.\n\n\n\nSubmission Instructions\nThis is an individual assignment. You are required to work on the take-home exercises and prepare submission individually.\nThe specific submission instructions are as follows:\n\nThe analytical visualisation must be prepared by using Tableau Desktop. The final workbook must be uploaded onto Tableau Public.\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nProvide the links to the Take-home Exercise write-up, github repository and Tableau Public onto eLearn (i.e. Take-home Exercise section)\n\n\n\nSubmission date\nYour completed take-home exercise is due on 22nd January 2023, by 11:59pm evening.\n\n\nPeer Learning\n\nAISHWARYA SANJAY MALOO\nANICA CLARICE ANTONELLA PASCUAL GALANO\nARIANA TAN RUI MIN\nBHAIRAVI VAIRAVELU\nBRYANT PHILIPPE LEE\nCHAN JING WEI MAGDALENE\nCHANG XIN XIN EDA\nCHEN YIMAN\nCHERYL JEANNE CHIEW\nCHOI SUNHAM\nFARRAH BINTE MOHD FADIL\nHOANG HUY\nHOU TAO\nHUO DA\nKHOO WEI LUN\nLAU ZHI YONG WILLIE\nLAW MAN LONG\nLAW SHIANG ROU\nLI XINGYUN\nLI YIXUAN\nLI ZIYI\nLIANG MINGHAO\nLIM EN HUI CHRISTIANA\nLUO ZHENG\nMICHAEL KEVIN WIRATAMA DJOHAN\nPRACHI RAJENDRA ASHANI\nSHI CHEE LIANG\nSIDDHARTH SINGH\nSRIVATSAN MADAPUZI SRINIVASAN\nTAN ZEXEONG\nTAN ZHI HAO\nTAO MEIZHU\nTASAPORN VISAWAMETEEKUL\nWANG KUNRUI\nWANG RUIPENG\nXU JIAJIE\nYIN HANG\nYUN SHWE YEE KYAW\nZHU FANGYUAN"
  },
  {
    "objectID": "take-home_ex/TH_EX02.html",
    "href": "take-home_ex/TH_EX02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "The Task\nIn this take-home exercise, you are required to:\n\nselect one of the Take-home Exercise 1 prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices you had learned in Lesson 1 and 2, and\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages.\n\nThe purpose of DataVis Makeover is to improve on the original visualisation. Focus on what works, what doesn’t work, why those things don’t work, and how you made it better. You should try stick to the fields in the data set provided and improve upon the original visualisation.\n\n\nSubmission Instructions\nThis is an individual assignment. You are required to work on the take-home exercises and prepare submission individually.\nThe specific submission instructions are as follows:\n\nThe analytical visualisation must be prepared by using R and appropriate R packages.\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nProvide the links to the Take-home Exercise write-up and github repository onto eLearn (i.e. Take-home Exercise section)\n\n\n\nSubmission date\nYour completed take-home exercise is due on 29th January 2023, by 11:59pm evening.\n\n\nLearning from senior\n\nSample 1\nSample 2\n\n\n\nPeer Learning\n\nAISHWARYA SANJAY MALOO\nANICA CLARICE ANTONELLA PASCUAL GALANO\nARIANA TAN RUI MIN\nBHAIRAVI VAIRAVELU\nBRYANT PHILIPPE LEE\nCHAN JING WEI MAGDALENE\nCHANG XIN XIN EDA\nCHEN YIMAN\nCHERYL JEANNE CHIEW\nCHOI SUNHAM\nFARRAH BINTE MOHD FADIL\nHOANG HUY\nHOU TAO\nHUO DA\nKHOO WEI LUN\nLAU ZHI YONG WILLIE\nLAW MAN LONG\nLAW SHIANG ROU\nLI XINGYUN\nLI YIXUAN\nLI ZIYI\nLIANG MINGHAO\nLIM EN HUI CHRISTIANA\nLUO ZHENG\nMICHAEL KEVIN WIRATAMA DJOHAN\nPRACHI RAJENDRA ASHANI\nSHI CHEE LIANG\nSIDDHARTH SINGH\nSRIVATSAN MADAPUZI SRINIVASAN\nTAN ZEXEONG\nTAN ZHI HAO\nTAO MEIZHU\nTASAPORN VISAWAMETEEKUL\nWANG KUNRUI\nWANG RUIPENG\nXU JIAJIE\nYIN HANG\nYUN SHWE YEE KYAW\nZHU FANGYUAN"
  },
  {
    "objectID": "take-home_ex/TH_EX03.html",
    "href": "take-home_ex/TH_EX03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "In this take-home exercise, you are required to uncover the salient patterns of the resale prices of public housing property by residential towns and estates in Singapore by using appropriate analytical visualisation techniques learned in Lesson 4: Fundamentals of Visual Analytics. Students are encouraged to apply appropriate interactive techniques to enhance user and data discovery experiences.\nFor the purpose of this study, the focus should be on 3-ROOM, 4-ROOM and 5-ROOM types. You can choose to focus on either one housing type or multiple housing types. The study period should be on 2022."
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#the-data",
    "href": "take-home_ex/TH_EX03.html#the-data",
    "title": "Take-home Exercise 3",
    "section": "The Data",
    "text": "The Data\nResale flat princes based on registration date from Jan-2017 onwards should be used to prepare the analytical visualisation. It is available at Data.gov.sg."
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#the-designing-tool",
    "href": "take-home_ex/TH_EX03.html#the-designing-tool",
    "title": "Take-home Exercise 3",
    "section": "The Designing Tool",
    "text": "The Designing Tool\nFor the purpose of this take-home exercise, ggplot2 and its extension should be used to design the analytical visualisation. tidyverse family of packages should be used to prepare the data."
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#the-write-up",
    "href": "take-home_ex/TH_EX03.html#the-write-up",
    "title": "Take-home Exercise 3",
    "section": "The Write-up",
    "text": "The Write-up\nThe write-up of the take-home exercise should include but not limited to the followings:\n\nDescribe the selection and designed consideration of the analytical data visualisation used. The discussion should limit to not more than 150 words each.\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the peer submission I shared.\nA write-up of not more than 100 words to discuss the patterns reveal by each analytical visualisation prepared."
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#submission-instructions",
    "href": "take-home_ex/TH_EX03.html#submission-instructions",
    "title": "Take-home Exercise 3",
    "section": "Submission Instructions",
    "text": "Submission Instructions\nThis is an individual assignment. You are required to work on the take-home exercises and prepare submission individually.\nThe specific submission instructions are as follows:\n\nThe analytical visualisation must be prepared by using R and appropriate R packages.\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nProvide the links to the Take-home Exercise write-up and github repository onto eLearn (i.e. Take-home Exercise section)"
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#submission-date",
    "href": "take-home_ex/TH_EX03.html#submission-date",
    "title": "Take-home Exercise 3",
    "section": "Submission date",
    "text": "Submission date\nThe completed take-home exercise is due on 15th February 2023, by 11:59pm evening."
  },
  {
    "objectID": "take-home_ex/TH_EX03.html#peer-learning",
    "href": "take-home_ex/TH_EX03.html#peer-learning",
    "title": "Take-home Exercise 3",
    "section": "Peer Learning",
    "text": "Peer Learning"
  },
  {
    "objectID": "take-home_ex/TH_EX04.html",
    "href": "take-home_ex/TH_EX04.html",
    "title": "Take-home Exercise 4",
    "section": "",
    "text": "In this take-home exercise, you are required to uncover the impact of COVID-19 as well as the global economic and political dynamic in 2022 on Singapore bi-lateral trade (i.e. Import, Export and Trade Balance) by using appropriate analytical visualisation techniques learned in Lesson 6: It’s About Time. Students are encouraged to apply appropriate interactive techniques to enhance user and data discovery experiences."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#the-data",
    "href": "take-home_ex/TH_EX04.html#the-data",
    "title": "Take-home Exercise 4",
    "section": "The Data",
    "text": "The Data\nFor the purpose of this take-home exercise, Merchandise Trade provided by Department of Statistics, Singapore (DOS) will be used. The data are available under the sub-section of Merchandise Trade by Region/Market. You should download the data by clicking on the link Download all in Excel on the same webpage. The study period should be between January 2020 to December 2022."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#the-designing-tool",
    "href": "take-home_ex/TH_EX04.html#the-designing-tool",
    "title": "Take-home Exercise 4",
    "section": "The Designing Tool",
    "text": "The Designing Tool\nFor the purpose of this take-home exercise, ggplot2 and its extension should be used to design the analytical visualisation. tidyverse family of packages should be used to prepare the data."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#the-write-up",
    "href": "take-home_ex/TH_EX04.html#the-write-up",
    "title": "Take-home Exercise 4",
    "section": "The Write-up",
    "text": "The Write-up\nThe write-up of the take-home exercise should include but not limited to the followings:\n\nDescribe the selection and designed consideration of the analytical data visualisation used. The discussion should limit to not more than 150 words each.\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the peer submission I shared.\nA write-up of not more than 100 words to discuss the patterns reveal by each analytical visualisation prepared."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#submission-instructions",
    "href": "take-home_ex/TH_EX04.html#submission-instructions",
    "title": "Take-home Exercise 4",
    "section": "Submission Instructions",
    "text": "Submission Instructions\nThis is an individual assignment. You are required to work on the take-home exercises and prepare submission individually.\nThe specific submission instructions are as follows:\n\nThe analytical visualisation must be prepared by using R and appropriate R packages.\nThe write-up of the take-home exercise must be in Quarto html document format. You are required to publish the write-up on Netlify.\nProvide the links to the Take-home Exercise write-up and github repository onto eLearn (i.e. Take-home Exercise section)"
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#submission-date",
    "href": "take-home_ex/TH_EX04.html#submission-date",
    "title": "Take-home Exercise 4",
    "section": "Submission date",
    "text": "Submission date\nThe completed take-home exercise is due on 26th February 2023, by 11:59pm evening."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#learning-from-senior",
    "href": "take-home_ex/TH_EX04.html#learning-from-senior",
    "title": "Take-home Exercise 4",
    "section": "Learning from senior",
    "text": "Learning from senior\n\nKELLY KOH KIA WOON DataViz Makeover write-up on Netlify and Tableau Public link. A must read submission.\nHow has Singapore changed since 2011? by Raymond TEO LIP PENG. This submission provides an useful reference on how to create animated motion plot by using time-oriented data.\nSingapore’s Demographic Composition Across Time by DENISE ADELE CHUA HUI SHAN. This submission provides interesting approaches to reveal values change over time without having to use animation."
  },
  {
    "objectID": "take-home_ex/TH_EX04.html#peer-learning",
    "href": "take-home_ex/TH_EX04.html#peer-learning",
    "title": "Take-home Exercise 4",
    "section": "Peer Learning",
    "text": "Peer Learning"
  },
  {
    "objectID": "VAProject.html",
    "href": "VAProject.html",
    "title": "Visual Analytics Project",
    "section": "",
    "text": "The purpose of the project is to provide students first hand experience on building web-enabled visual analytics application by using R Shiny. It aims to democratize data and analytics. Hence, the application focuses and emphasises on interactivity and effective integration of techniques from data analytics and data visualization.\nA project may involve developing new methods or implementing visual analytics system to support analytic tasks in specific domains. Alternatively, a project may be in the form of application development by integrating analytical tools within a visual analytics environment. Students are encouraged to focus on research topics that are relevant to their field of study. It should address a concrete visual analytics problem and should propose a novel and creative solution."
  },
  {
    "objectID": "VAProject.html#project-topic",
    "href": "VAProject.html#project-topic",
    "title": "Visual Analytics Project",
    "section": "Project Topic",
    "text": "Project Topic\nThe followings are possible topic and data sources:\n\nLandslide Prevention and Innovation Challenge\nData Science Nigeria Challenge #1: Loan Default Prediction\nFraud Detection in Electricity and Gas Consumption Challenge\nAgriFieldNet India Challenge"
  },
  {
    "objectID": "VAProject.html#project-management",
    "href": "VAProject.html#project-management",
    "title": "Visual Analytics Project",
    "section": "Project Management",
    "text": "Project Management\nThe project is team work. Students are required to form a project team of 2-3 members by the first week of the academic term.\nA good group project is a system consisting of a collection of well defined sub-modules. Each sub-module should be the responsibility of one person and be clearly identified as their project. A good criteria for whether you should work in a group is whether the system as a whole is greater than the sum of its parts!\nEach project team are required to maintain a comprehensive Minutes of Meeting from the beginning of the project until the end of the project. Each minutes of meeting should include but not limit to the discussion, disagreements, and consensus made and action items agreed within the team. The Minutes of Meeting should also record the division of labour and the considerations involved in the decision made.\nThe following links provided useful guides on how to prepare the minutes of a meeting:\n\nHow to Write Meeting Minutes: Examples + Best Practices\nHow To Write Effective Meeting Minutes(with Templates and Samples)\n\nThe Minutes of Meeting must be uploaded on eLearn within 24hrs after the meeting ended."
  },
  {
    "objectID": "VAProject.html#project-milestone",
    "href": "VAProject.html#project-milestone",
    "title": "Visual Analytics Project",
    "section": "Project Milestone",
    "text": "Project Milestone\n\nBrainstorming project ideas and consulting with course instructor anytime from week 1 onward.\nEditing and publishing project proposal on Netlify latest by the end of week 5.\nSubmission of final application, user guide, project poster and artifacts: 2nd April 2023 by 11:59pm (mid-night)"
  },
  {
    "objectID": "VAProject.html#project-deliverables",
    "href": "VAProject.html#project-deliverables",
    "title": "Visual Analytics Project",
    "section": "Project Deliverables",
    "text": "Project Deliverables\n\nProject Github\nAt the beginning of the project, project teams are required to create a project Github. The project Github should include all the materials used to develop the project and the written materials such as proposal, poster and practice research paper. It must be used to maintain a complete project version control including the application and project documents. The Github link must be included in the project proposal. By the end of the project, the project team must pack the final version of the Github repository and upload onto eLearn for final submission. The Github link also must be provided on eLearn.\n\n\nProject Website\nEach project team are required to create the project website by using Quarto. It will be disseminated by using webserver such as Netfity.\nAs a first step, you should create a project summary at the project website that includes:\n\nThe title of your project,\nA short description of not more than 350 word summarising the motivation, objectives, main features of the application your team are going to build, and\nThe project proposal. This should in a webpage (remember to provide a link at the wiki).\n\n\n\nProject proposal\nEach project teams must start thinking about their project ideas after the Shiny Workshop. They are expected to discuss their project topic and scope of works with the instructor from week 1 onward. A project proposal in the form of website edited using Quarto will be prepared and the link must be provided on eLearn by 12th Feb 2023.\nThe project proposal should describe the motivation of the project, problems or issues that the project will address, the relevant related work, the approach the team plans to take to solve the problem, and early prototypes or storyboards. The project teams should take advantage of this proposal as a chance to get feedback on the direction of the project from their peers.\nStudents are required to update their project websites with all the details including the final application, user guide and poster by 2nd April 2023.\n\n\nPoster\nThe project poster should provide an overview of your project. It should include, but not limited to the following information:\n\nIssues and problems - A clear statement of the issues or/and problems your project addresses.\nMotivation - An explanation of why the issues and/or problems are interesting and what make them difficult to solve.\nApproach - A description of the techniques or algorithms you used to solve the problem.\nResults - Screenshots and a working demo of the system you built.\nFuture Work - An explanation of how the work could be extended.\n\nThe dimensions for the poster must conform to the International Standards Organization (ISO) poster size format (A1).\n\nSize = ISO A1 (594 × 841mm or 23.39 × 33.11inci)\nResolution = 300dpi or above\nFile format = jpeg or pdf\n\nPlease ensure that the poster is in high resolution.\nNote: The poster will be considered a final deliverable, so don’t forget to apply good visual design and data visualisation principles and best practice to your poster.\n\n\nFinal Deliverables\nThe final deliverable will include:\n\nDeployment of the Web-enabled Visual Analytics Application on shinyapps.io by RStudio.\nartifact including the ShinyApp codes, data and all r modules.\nUser Guide - Step-by-step guide on how to use the data visualisation functions designed.\n\nSample UserGuide 1\nSample UserGuide 2\n\nProject poster\nMinutes of Meeting\n\nThe final deliverable must be uploaded into the Dropbox of e-Learn (e.g. LMS). It must in a single zip file format."
  },
  {
    "objectID": "VAProject.html#grading",
    "href": "VAProject.html#grading",
    "title": "Visual Analytics Project",
    "section": "Grading",
    "text": "Grading\nThe visual analytics project will account for 30% of your final grade in the course. The distribution of marks for each stage of the project are as follows:\n\nProject website 20%\nPoster 15%\nMinutes of Meeting 15%\nShinyApp 50%\n\nThe course instructor will consider strongly the novelty of the idea (If it has never been done before, you will get lots of credit!), how it addresses the problem at hand, the methodology you employ in doing the research, and your technical skill in implementing the idea.\n\nGrading criteria for poster\nThe poster will be graded based on the following criteria:\n\nClear communication of key aspects of solution\nClear communication of design approaches\nClear communication of arguments for proposed solution\nCraft quality of the solution"
  },
  {
    "objectID": "VAProject.html#sample-projects",
    "href": "VAProject.html#sample-projects",
    "title": "Visual Analytics Project",
    "section": "Sample Projects",
    "text": "Sample Projects\nNote that the following examples are for references purposes. You are urge to use your own creativity and innovation to design the application\n\nMITB (Analytics)\n\nISSS608 Year 2013-14 Term 3B\nISSS608 Year 2014-15 Term 3B\nISSS608 Year 2015-16 Term 1\n\nOooh Shiny!\nKong Simi - A visual earpiece into the Singapore Parliament\n\nISSS608 Year 2016-17 Term 1\n\nProject A - The Non-Conventional Sales Dashboard for Company A\nDashboardViz\n\nISSS608 Year 2016-17 Term 3\n\nVRshiny: An Application for better business decision making - Visualizing Association Rules with Network Diagram in Shiny\nDiscovering traffic patterns by using network graph visualisations. In this project, the students developed their project by using VAST Challenge data sets and scenario. However, the project was not a direct replicate of their assignments. \n\nISSS608 Year 2017-18 Term 1\nISSS608 Year 2017-18 Term 3\n\nSingapore Property Market Watch - Your new tool to visualize SG Property Trend\n\nISSS608 Year 2018-19 Term 1\n\nCorn: The A-maize-ing Crop\n\nISSS608 Year 2018-19 Term 3\n\nHow healthy is your neighbourhood?\nAn Interactive Shiny web Application to study the past trends and forecast of tourists to Singapore\n\nISSS608 Year 2019-20 Term 2\n\nSGSAS: Simple Geo-Spatial Analysis using R-Shiny\nA Visual Exploration of Media Consumption in Singapore\n\nISSS608 Year 2020-21 Term 2\nISSS608 Year 2021-22 January Term\n\nGroup 1: Money Not Enough: A Deep Dive into Singapore’s Shopping Basket\nGroup 5: How to spot a Golden Goose (a.k.a. Profitable Rental Property) in Singapore\nGroup 6: ShinyCoin."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-cycle-plot",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Cycle Plot",
    "text": "Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nSrep 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-slopegraph",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-slopegraph",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice <- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %>% \n  mutate(Year = factor(Year)) %>%\n  filter(Year %in% c(1961, 1980)) %>%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-horizon-plot",
    "href": "hands-on_ex/Hands-on_Ex06/Hands-on_Ex06-VisTime.html#plotting-horizon-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Horizon Plot",
    "text": "Plotting Horizon Plot\nIn this section, you will learn how to plot a horizon graph by using ggHoriPlot package.\nBefore getting start, make sure that ggHoriPlot has been included in the pacman::p_load(...) statement above. Then, refer to Getting Started to learn more about the function. Lastly, read [geom_horizon()](https://rivasiker.github.io/ggHoriPlot/reference/geom_horizon.html to learn more about the usage ot its arguments.\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\naverp <- read_csv(\"data/AVERP.csv\") %>%\n  mutate(`Date` = dmy(`Date`))\n\n\n\n\n\n\n\nThing to learn from the code chunk above.\n\n\n\n\nBy default, read_csv will import data in Date field as Character data type. dmy() of lubridate package to palse the Date field into appropriate Date data type in R.\n\n\n\n\n\n\nStep 2: Plotting the horizon graph\nNext, the code chunk below will be used to plot the horizon graph.\n\naverp %>% \n  filter(Date >= \"2018-01-01\") %>%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#what-will-you-learn-from-this-lesson",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#what-will-you-learn-from-this-lesson",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "What will you learn from this lesson?",
    "text": "What will you learn from this lesson?\n\nIntroducing map\nProperties of geographical data\n\nGeographical data models\nMap projections\n\nTypology of maps\n\nReference maps\nThematic maps\n\nProportional Symbol Map\nChoropleth Map]"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#what-is-a-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#what-is-a-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "What is a Map?",
    "text": "What is a Map?\nA map is a model of real world depict by a collection of cartographic symbols or/and visual abstraction."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#what-is-a-map-1",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#what-is-a-map-1",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "What is a Map?",
    "text": "What is a Map?\nAn interface between geographical data and map users."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#a-map-and-geographical-data",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#a-map-and-geographical-data",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "A Map and Geographical Data",
    "text": "A Map and Geographical Data"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#types-of-geographical-data",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#types-of-geographical-data",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Types of geographical data",
    "text": "Types of geographical data"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "How location information are registered?",
    "text": "How location information are registered?\n\nGeographic Coordinates Systems\nProjected Coordinates Systems"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered-1",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered-1",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "How location information are registered?",
    "text": "How location information are registered?\n\nGeographic Coordinates Systems\n\n\n\nA geographic coordinate system defines two-dimensional coordinates based on the Earth’s surface. It has an angular unit of measure, prime meridian and datum (which contains the spheroid).\nFor example, WGS84, NAD27 and NAD83.\n\n\nSource: Geographic Coodinate Ststem@wiki"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered-2",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#how-location-information-are-registered-2",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "How location information are registered?",
    "text": "How location information are registered?\n\nProjected Coordinates Systems\n\n\n\nA projected coordinate system is defined on a flat, two-dimensional surface.\nA projected coordinate system, unlike a geographic one, has the advantage that lengths, angles, and areas are constant across the two dimensions. This is not true when working in a geographic coordinate system.\nA projected coordinate system is always based on a geographic coordinate system that can use a sphere or spheroid.\n\n\n\n\nSource: Map Projection@wiki"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "The Purpose of a Map",
    "text": "The Purpose of a Map\n\nTo serve as a piece of historical archive.\n\n\n\nSource: Battle of Singapore\n\n\nA map serves as a record of the physical and cultural environment at a particular time. For example, the map above shows Singapore in early February 1942; the disposition of Allied ground forces is in red. The main north–south transport corridor, formed by Woodlands Road and the railway, connecting the city centre (in the southeast) and The Causeway (central north), is the black line running through the centre of the island. Sarimbun is at the north west corner of the island; Bukit Timah is located close to the centre on the transport corridor; Pasir Panjang is between the city centre and the southwest corner of the island and the “Jurong Line” is the bracket-like shape in red, just west of Woodlands Roadland use allocation on Singapore Concept Plan in 2001."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-1",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-1",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "The Purpose of a Map",
    "text": "The Purpose of a Map\n\nTo support navigation (i.e. Google Map)."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-2",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-2",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "The Purpose of a Map",
    "text": "The Purpose of a Map\n\nTo support navigation (i.e. sea chart of Singapore)\n\n\n\nSource: Singapore electronic navigational chart"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-3",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-3",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "The Purpose of a Map",
    "text": "The Purpose of a Map\n\nTo reveal spatial patterns.\n\n\n\n\n\n\n\nReference: John Snow Cholera Map"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-4",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#the-purpose-of-a-map-4",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "The Purpose of a Map",
    "text": "The Purpose of a Map\n\nTo describe spatial relationship."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#typology-of-maps",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#typology-of-maps",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Typology of Maps",
    "text": "Typology of Maps\n\n\n\nReference maps\n\n\n\nReference maps emphasize the location of spatial phenomena, such buildings, roads, vegetations, rivers, etc. Some of popular reference maps are topographical map and internet map such as Google map.\n\n\n\n\n\n\nTopographic maps are detailed, accurate graphic representations of features that appear on the Earth’s surface. These features include: cultural: roads, buildings, urban development, railways, airports, names of places and geographic features, administrative boundaries, state and international borders, reserves hydrography: lakes, rivers, streams, swamps, coastal flats relief: mountains, valleys, slopes, depressions vegetation: wooded and cleared areas, vineyards and orchards.\nA map legend (or key) lists the features shown on that map, and their corresponding symbols. Topographic maps usually show a geographic graticule and a coordinate grid, so you can determine relative and absolute positions of mapped features.\nIt is important to note that a map is merely a two or three dimensional representation of the physical environment at a given time. Therefore, a map will never be entirely up to date. Changes to the landscape and cultural features regularly occur (such as roads, vegetation, and buildings), resulting in maps becoming dated, although the rate of obsolescence varies depending upon location. Traditionally present in paper printed format.\n\n\n\n\nThematic Map\n\n\n\nThematic maps emphasize the spatial pattern of geographic attributes or statistics about places and relationships between places such as Life in Los Angeles.\n\n\nSource: Life in Los Angeles"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#thematic-mapping-principles-and-methods",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#thematic-mapping-principles-and-methods",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Thematic Mapping: Principles and Methods",
    "text": "Thematic Mapping: Principles and Methods\n\nDisplaying\n\nQualitative data\nQuantitative data\n\nChoosing -Appropriate classification method for displaying data\n\nAppropriate number of classes\n\nTechniques in data analysis\n\nUsing the classification histogram\nNormalizing data"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-maps",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-maps",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Qualitative Thematic Maps",
    "text": "Qualitative Thematic Maps\n\nVisual Variables and Cartographic Symbols\n\n\n\nQualitative visual variables are used for nominal scale data.\nThe goal of qualitative visual variables is to show how entities differ from each other.\nThe visual variables that do a good job of showing ordinal differences are: colour value, colour saturation, size and texture/grain.\n\nFigure on the right for examples of these four ordinal visual variables used each in point, linear and areal symbols."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\nPoint symbol map\n\n\n\nDifferent point symbols are used to represent school types."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map-1",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map-1",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\nLine symbol map\n\n\n\nA road map is an example of a thematic map. It shows the road network of an area. In this map, lines with different colour intensity and tickness are used to differentiate hierarchy of roads."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map-2",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#qualitative-thematic-map-2",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Qualitative Thematic Map",
    "text": "Qualitative Thematic Map\n\nArea map\n\n\n\nLand use map below is a good example of a discrete thematic map. In this map, different colours are use to represent different land use types."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#quantitative-thematic-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#quantitative-thematic-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Quantitative Thematic Map",
    "text": "Quantitative Thematic Map\n\nVisual Variables and Cartographic Symbols\n\n\n\nQuantitative visual variables are used to display ordinal, interval or ratio scale data.\n\nThe goal of the quantitative visual variable is to show relative magnitude or order between entities.\nThe visual variables that do a good job of showing ordinal differences are: colour value, colour saturation, size and texture/grain.\n\nFigure on the right shows of these four ordinal visual variables used each in point, linear and areal symbols."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#proportional-symbol-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#proportional-symbol-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Proportional Symbol Map",
    "text": "Proportional Symbol Map\n\nThe proportional symbol technique uses symbols of different sizes to represent data associated with different areas or locations within the map.\n\n\n\nThe proportional symbol technique uses symbols of different sizes to represent data associated with different areas or locations within the map. For example, the proportional maps above use circle with different sizes to represent millions of people. There are two types of point features that are typically depicted with proportional symbols: features for which the data represents a geographic position directly (e.g., gallons of oil from individual oil wells), and features that are geographic areas to which data are aggregated and the data magnitudes are assigned to a representative point within the area (e.g., the geographic centroid of a state as in the examples above). In either case, the area of the symbol is scaled to represent the data magnitude, sometimes with a bit of exaggeration to adjust for a general tendency of human vision to underestimate differences in area. A variant on this direct data-to-symbol scaling groups values into categories first, then scales the symbol to represent the mean for the category, assigning a symbol to each place to represent the category range that the mean for the place falls within\n\n\n\nHow to size circles incorrectly and correctly?\nFigure below explains how attribute values are map on circles. One strategy to overcome this problem is to use square instead of circle.\n\n\n\n\nHow to make proportional symbol maps clearer?\nWhen designing a proportional symbol map, one of the important consideration is to avoid the circles blocking each other. One possible strategy to overcome this problem is to applying opacity (also known as transparency).\n\n\n\n\nProportional Symbol Map: Pie Chart Map\nOne important characteristic of proportional symbols is that they can easily be designed to represent more than one data value per location. Among the most common example is a pie chart map in which a circle is scaled proportionally to some total, and the size of wedges within the circle is scaled to depict a proportion of a total for two or more sub-categories.\n\n\nOne important characteristic of proportional symbols is that they can easily be designed to represent more than one data value per location. Among the most common example is a “pie chart map” in which a circle is scaled proportionally to some total, and the size of wedges within the circle is scaled to depict a proportion of a total for two or more sub-categories. The map above uses circle size to depict total sales in each city, and the pie slices then depict proportion of the three shipping modes, namely: delivery truck, express air and regular air.\n\n\n\n\nProportional Symbol Map: Bar Chart Map\nProportional side-by-side bar map places side-by-side bar chart on a map based on the location of the observations.\n\n\n\n\nProportional Symbol Map - Junk Map\nWhen preparing a proportional symbol map, it is important to ensure that the geographical level used is the same.\n\n\nSource: COVID-19 Dashboard\n\n\n\n\nAltertive of Proportional Symbol Map: Bricks Map\nBricks Map aims to provide better ways to encode quantitative information graphically—ways that can be easily, efficiently, and accurately decoded.\n\n\nSource: Building insight with bricks.\n\n\n\n\nBricks Map versus Proportional Symbol Map\nBy plotting a proportional symbol map and a bricks map side-by-side as shown below, it is clear that bubbles of graduated sizes proportional to the value ranges that they represent can be difficult to distinguish than the bricks."
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#dot-density-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#dot-density-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Dot Density Map",
    "text": "Dot Density Map\nA dot-density map is a type of thematic map that uses dots or other symbols on the map to show the values of one or more numeric data fields. Each dot on a dot-density map represents some amount of data.\n\n\nOne dot represent 100 households.\n\n\nReference: Dot distribution map at wiki and Dot Density Maps"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#choropleth-map",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#choropleth-map",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Choropleth Map",
    "text": "Choropleth Map\nA choropleth map is a type of thematic map in which areas are shaded or patterned in proportion to a statistical variable that represents an aggregate summary of a geographic characteristic within each area, such as population or per capita income.\n\n\n\nClassified choropleth map\n\nA choropleth map can be either classified or unclassified.\nA classed choropleth map combines areal units into a smaller number of groups. Interval levels may vary, but typically 4 to 7 are used in a map. There is different classification techniques used to divide up the intervals.\n\n\n\n\n\nUnclassified choropleth map\n\nAn unclassified choropleth map is similar to a classed choropleth map; however, an unclassed choropleth maps do not have an averaged statistic towards each particular colour.\n\n\n\n\n\nChoropleth mapping technique - Number of classes\nThe readability of a choropleth map will be affected by the number of classes used.\n\n\n\nWhen a small number of classes is used, the spatial distribution reveals will be very limited.\n\n\n\n\nWhen an appropriate number of classes is used, the spatial distribution reveals will be clear.\n\n\n\n\n\n\n\nChoropleth mapping technique: Number of classes\nFigure below provided a mathematical method to determine number of classes used for preparing a choropleth map.\n\n\n\n\nChoropleth mapping technique: Methods of choosing classification scheme\n\nBased on the nature of the distribution\n\nquantile, equal interval, natural breaks, standard deviations, defined interval\n\nArbitrary\n\nCan be based on round numbers.\nExamples: Grouping according to age or census housing categories\nCan result in empty categories\n\n\n\n\n\nData classification method: Equal interval\n\nDivides the range of attribute values into equally sized classes.\n\n\n\n\n\nData classification method: Quantitle\n\nSame number of features per class.\n\n\n\n\n\n\n\n\n\nData classification method: Jenks (also known as Natural breaks)\n\nDefault Jenk’s statistical optimization by finds natural groupings in the data.\n\n\n\n\n\nData classification method: Standard deviation\n\nA measure of dispersion. Use if the distribution approximates a normal distribution.\n\n\n\n\n\nChoropleth map - Colour scheme\nColorBrewer is an online tool designed to help people select good color schemes for maps and other graphics.\n\n\n\n\nColour Scheme Tip\n\nAvoiding multiple colours in choropleth mapping\nStick with a single hue (or a small set of closely related hues) and vary intensity from pale colours for low values to increasingly darker and brighter colours for high values.\n\n\n\n\n\nTrellis choropleth map\n\n\n\nTrellis maps , also known as small multiple maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically.\nSmall multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\n\n\n\n\n\n\n\n\nGeofacet\nGeofacet takes data representing different geographic entities and apply a visualization method to the data for each entity, with the resulting set of visualizations being laid out in a grid that mimics the original geographic topology as closely as possible.\n\n\nSource: Singapore Property Market Watch"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html#reference",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html#reference",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "Reference",
    "text": "Reference\nProportional Symbols\nChoropleth Maps\nDot Density Maps\nThe Basics of Data Classification\nShould a map be interactive?\nMap interaction"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html",
    "title": "Hands-on Exercise 7: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#getting-started",
    "title": "Hands-on Exercise 7: Analytical Mapping",
    "section": "2 Getting Started",
    "text": "2 Getting Started\n\n2.1 Installing and loading packages\n\n\n\n\n\n\nYour turn\n\n\n\nUsing the steps you learned in previous lesson, install and load sf, tmap and tidyverse packages into R environment.\n\n\n\n\n\nShow the code\npacman::p_load(tmap, tidyverse, sf)\n\n\n\n\n\n2.2 Importing data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\n\n\n\n\n\nDo it Yourself\n\n\n\nUsing appropriate sf function import NGA_wp.rds into R environment.\n\n\n\n\n\nShow the code\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#basic-choropleth-mapping",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#basic-choropleth-mapping",
    "title": "Hands-on Exercise 7: Analytical Mapping",
    "section": "3 Basic Choropleth Mapping",
    "text": "3 Basic Choropleth Mapping\n\n3.1 Visualising distribution of non-functional water point\n\n\n\n\n\n\nYour turn\n\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA\n\n\n\n\n\nShow the code\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\n\n\nShow the code\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\n\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#choropleth-map-for-rates",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#choropleth-map-for-rates",
    "title": "Hands-on Exercise 7: Analytical Mapping",
    "section": "4 Choropleth Map for Rates",
    "text": "4 Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n4.1 Deriving Proportion of Functional Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n4.2 Plotting map of rate\n\n\n\n\n\n\nYour turn\n\n\n\nPlot a choropleth map showing the distribution of percentage functional water point by LGA\n\n\n\n\n\nShow the code\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#extreme-value-maps",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Analytical_Mapping.html#extreme-value-maps",
    "title": "Hands-on Exercise 7: Analytical Mapping",
    "section": "5 Extreme Value Maps",
    "text": "5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n5.1.1 Data Preparation\nStep 1: Exclude records with NA by using the code chunk below.\n\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\n\nStep 2: Creating customised classification and extracting values\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\n\n\n5.1.2 Why writing functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n5.1.3 Creating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n5.1.4 A percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n5.2 Box map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map)\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "lesson/Lesson07/Lesson07-VisGeo.html",
    "href": "lesson/Lesson07/Lesson07-VisGeo.html",
    "title": "Lesson 7: Visualising and Analysing Geographic Data",
    "section": "",
    "text": "Introducing map\nProperties of geographical data\n\nGeographical data models\nMap projections\n\nTypology of maps\n\nReference maps\nThematic maps\n\nProportional Symbol Map\nChoropleth Map]"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html",
    "title": "Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nIn this chapter, you will learn how to plot functional and truthful choropleth maps by using an R package called **tmap** package.\n\n\nIt is advisable for you to read the functional description of each function before using them."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#getting-started",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#getting-started",
    "title": "Choropleth Mapping with R",
    "section": "Getting Started",
    "text": "Getting Started\nIn this hands-on exercise, the key R package use is tmap package in R. Beside tmap package, four other R packages will be used. They are:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAmong the four packages, readr, tidyr and dplyr are part of tidyverse package.\nThe code chunk below will be used to install and load these packages in RStudio.\n\npacman::p_load(sf, tmap, tidyverse)\n\nNotice that, we only need to install tidyverse instead of readr, tidyr and dplyr individually."
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#importing-data-into-r",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#importing-data-into-r",
    "title": "Choropleth Mapping with R",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\n\n\nImporting Geospatial Data into R\nThe code chunk below uses the st_read() function of sf package to import MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame called mpsz.\n\nmpsz <- st_read(dsn = \"data/geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\tskam\\ISSS608-AY2022-23Jan\\hands-on_ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nYou can examine the content of mpsz by using the code chunk below.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNotice that only the first ten records will be displayed. Do you know why?\n\n\nImporting Attribute Data into R\nNext, we will import respopagsex2000to2018.csv file into RStudio and save the file into an R dataframe called popagsex.\nThe task will be performed by using read_csv() function of readr package as shown in the code chunk below.\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")\n\n\n\nData Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\nData wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() of tidyr package, and\nmutate(), filter(), group_by() and select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nBefore we can perform the georelational join, one extra step is required to convert the values in PA and SZ fields to uppercase. This is because the values of PA and SZ fields are made up of upper- and lowercase. On the other, hand the SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Choropleth Mapping with R",
    "section": "Choropleth Mapping Geospatial Data Using tmap",
    "text": "Choropleth Mapping Geospatial Data Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\nPlotting a choropleth map quickly by using qtm()\nThe easiest and quickest to draw a choropleth map using tmap is using qtm(). It is concise and provides a good default visualisation in many cases.\nThe code chunk below will draw a cartographic standard choropleth map as shown below.\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\nCreating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nIn the following sub-section, we will share with you tmap functions that used to plot these elements.\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone, we just need to assign the target variable such as Dependency to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and *tm_border()**\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nNotice that the planning subzones are shared according to the respective dependecy values\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\nThe code chunk below shows a quantile data classification that used 5 classes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the distribution of quantile data classification method are more evenly distributed then equal data classification method.\n\nWarning: Maps Lie!\n\n\nDIY: Using what you had learned, prepare choropleth maps by using different classification methods supported by tmap and compare their differences.\n\n\nDIY: Preparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\n\n\n\nPlotting choropleth map with custome break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\nUsing ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nNotice that the colour scheme has been reversed.\n\n\n\nMap Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap style\ntmap allows a wide variety of layout settings to be changed. They can be called by using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\nDrawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nIn this example, small multiple choropleth maps are created by defining ncols in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\nIn this example, multiple small choropleth maps are created by using tm_facets().\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\nIn this example, multiple small choropleth maps are created by creating multiple stand-alone maps with tmap_arrange().\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\nMappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#reference",
    "href": "hands-on_ex/Hands-on_Ex07/Hands-on_Ex07-Choropleth_Mapping.html#reference",
    "title": "Choropleth Mapping with R",
    "section": "Reference",
    "text": "Reference\n\nAll about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\nGeospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\nData wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  }
]